# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.17.2
#   kernelspec:
#     display_name: Python [conda env:base] *
#     language: python
#     name: conda-base-py
# ---

# %%
import pandas as pd
import pandas_ta as ta
import numpy as np
import json
from datetime import datetime
import time
import math
import requests
import random


# %% [markdown]
# ### –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–µ—á–µ–π —Å Bybit –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞

# %%
# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞

def fetch_kline_data(symbol, tf, start_ms, end_ms, 
                    max_retries=5, 
                    max_consecutive_failures=4,
                    batch_size=200):
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–≤–µ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å Bybit
    —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–∫–∏ 403 –∏ —É–ª—É—á—à–µ–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    """
    url = "https://api.bybit.com/v5/market/kline"
    ms_tf = int(tf) * 60 * 1000
    batch_count = math.ceil((end_ms - start_ms) / (batch_size * ms_tf))
    
    all_data = []
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Referer': 'https://www.bybit.com',
        'Accept': 'application/json'
    }
    
    consecutive_failures = 0
    failed_batches = 0

    for i in range(batch_count):
        batch_start = start_ms + i * batch_size * ms_tf
        batch_end = min(end_ms, batch_start + batch_size * ms_tf)
        
        params = {
            'category': 'linear',
            'symbol': symbol,
            'interval': str(tf),
            'start': int(batch_start),
            'end': int(batch_end),
            'limit': str(batch_size)
        }

        current_batch_failed = True
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(random.uniform(0.1, 0.5))
                
                r = requests.get(url, params=params, headers=headers, timeout=15)
                
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ 403 –æ—à–∏–±–∫–∏
                if r.status_code == 403:
                    error_msg = r.json().get('retMsg', 'Unknown error')
                    raise requests.exceptions.HTTPError(
                        f"403 Forbidden: {error_msg}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ: "
                        "1) –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–∞\n"
                        "2) –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ä—ã–Ω–∫–∞\n"
                        "3) –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è API –∫–ª—é—á–µ–π\n"
                        "4) IP-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è"
                    )
                
                r.raise_for_status()
                data = r.json()
                
                # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
                if not data.get('result') or not isinstance(data['result'], dict):
                    raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ API")
                
                result_list = data['result'].get('list', [])
                if not result_list:
                    print(f"‚ö†Ô∏è {symbol} | –ë–∞—Ç—á {i+1}/{batch_count} | –ü—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ –¥–∞–Ω–Ω—ã—Ö")
                    break
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏
                df = process_batch_data(result_list)
                all_data.append(df)
                consecutive_failures = 0
                current_batch_failed = False
                break
                
            except requests.exceptions.HTTPError as e:
                last_error = str(e)
                if '403' in last_error:
                    print(f"üîí –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞: {last_error}")
                    return None
                print(f"‚ùå HTTP Error [{symbol} | –ë–∞—Ç—á {i+1}/{batch_count} | –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries}]: {last_error[:200]}")
                time.sleep(2 ** attempt + random.uniform(0.1, 1.0))
            except Exception as e:
                last_error = str(e)
                print(f"‚ùå –û—à–∏–±–∫–∞ [{symbol} | –ë–∞—Ç—á {i+1}/{batch_count} | –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries}]: {last_error[:200]}")
                time.sleep(2 ** attempt + random.uniform(0.1, 1.0))
        
        if current_batch_failed:
            consecutive_failures += 1
            failed_batches += 1
            print(f"üö´ –ë–∞—Ç—á {i+1}/{batch_count} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_error[:200]}")
            
            if consecutive_failures >= max_consecutive_failures:
                print(f"‚è© –ü—Ä–µ—Ä—ã–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É {symbol} (–ø–æ–¥—Ä—è–¥ {consecutive_failures} –Ω–µ—É–¥–∞—á–Ω—ã—Ö –±–∞—Ç—á–µ–π)")
                break

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if not all_data:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} –ø–æ—Å–ª–µ {failed_batches} –Ω–µ—É–¥–∞—á–Ω—ã—Ö –±–∞—Ç—á–µ–π")
        return None
        
    final_df = pd.concat(all_data).drop_duplicates().sort_values('Date').reset_index(drop=True)
    
    if failed_batches > 0:
        print(f"üü° {symbol} –∑–∞–≥—Ä—É–∂–µ–Ω —á–∞—Å—Ç–∏—á–Ω–æ: {len(all_data)}/{batch_count} –±–∞—Ç—á–µ–π")
    
    return final_df

def process_batch_data(result):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –±–∞—Ç—á–∞"""
    data = pd.DataFrame(result)
    return pd.DataFrame({
        'Date': pd.to_datetime(data.iloc[:, 0].astype('float'), unit='ms'),
        'Open': data.iloc[:, 1].astype('float'),
        'High': data.iloc[:, 2].astype('float'),
        'Low': data.iloc[:, 3].astype('float'),
        'Close': data.iloc[:, 4].astype('float'),
        'Volume': data.iloc[:, 5].astype('float')
    }).sort_values('Date')

def kline_candles(symbol, tf, start=None, end=None, n_candles=None, min_completeness=0.7):  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö (0.7 = 70%)
    try:
        ms_tf = int(tf) * 60 * 1000

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        if start and end:
            start_dt = datetime.strptime(start, "%Y-%m-%d %H:%M")
            end_dt = datetime.strptime(end, "%Y-%m-%d %H:%M")
            start_ms = int(start_dt.timestamp() * 1000)
            end_ms = int(end_dt.timestamp() * 1000)
            expected_candles = ((end_ms - start_ms) / ms_tf) + 1
        elif n_candles:
            end_ms = int(time.time() * 1000)
            start_ms = end_ms - n_candles * ms_tf
            expected_candles = n_candles
        else:
            return pd.DataFrame()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        full_df = fetch_kline_data(symbol, tf, start_ms, end_ms)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if full_df is None:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
            return pd.DataFrame()
            
        if full_df.empty:
            print(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π DataFrame –¥–ª—è {symbol}")
            return pd.DataFrame()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
        actual_candles = len(full_df)
        completeness = actual_candles / expected_candles
        
        if completeness < min_completeness:
            print(f"‚ö†Ô∏è {symbol} –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é: {actual_candles}/{int(expected_candles)} —Å–≤–µ—á–µ–π ({completeness:.1%})")
            return pd.DataFrame()

        full_df.dropna(inplace=True)
        
        if full_df.empty:
            print(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è {symbol}")
            
        return full_df
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ kline_candles –¥–ª—è {symbol}: {str(e)[:200]}")
        return pd.DataFrame()

# %% [markdown]
#

# %%

# %%

# %%
