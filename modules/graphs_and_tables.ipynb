{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c68db7-cca2-4279-be1a-d27955b1ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import joblib\n",
    "from typing import Any, Dict, List\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score, roc_auc_score, precision_recall_curve, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import shap\n",
    "from ipywidgets import widgets\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9179515-45a4-4e83-918a-4042836509d7",
   "metadata": {},
   "source": [
    "# –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f4cd0-c0fc-456a-a486-150079eb6b29",
   "metadata": {},
   "source": [
    "## plot_ohlc_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe253e7-a9e8-4e35-957a-5d87431c11d8",
   "metadata": {},
   "source": [
    "–†–∏—Å—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ OHLC —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π buy/sell —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ —à—É–º–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤\n",
    "    \n",
    "–ê—Ä–≥—É–º–µ–Ω—Ç—ã:\n",
    "- df —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ *'Open','High','Low','Close','buy','sell','buy_noised','sell_noised'*\n",
    "- **start_idx**: –Ω–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞\n",
    "- **end_idx**: –∫–æ–Ω–µ—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c480c2d7-d792-4c00-a025-fe13ea9dc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ohlc_signals(df, start_idx=0, end_idx=None):\n",
    "    \"\"\"\n",
    "    –†–∏—Å—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ OHLC —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π buy/sell —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ —à—É–º–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'Open','High','Low','Close','buy','sell','buy_noised','sell_noised'\n",
    "        start_idx: –Ω–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞\n",
    "        end_idx: –∫–æ–Ω–µ—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞\n",
    "    \"\"\"\n",
    "    if end_idx is None:\n",
    "        end_idx = len(df)\n",
    "    \n",
    "    plot_data = df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # –†–∏—Å—É–µ–º –≤—Å–µ —Ü–µ–Ω–æ–≤—ã–µ –ª–∏–Ω–∏–∏\n",
    "    plt.plot(plot_data.index, plot_data['Close'], 'b-', label='Close', linewidth=1.5)\n",
    "    plt.plot(plot_data.index, plot_data['Open'], 'g--', label='Open', linewidth=1, alpha=0.7)\n",
    "    plt.plot(plot_data.index, plot_data['High'], 'c:', label='High', linewidth=1, alpha=0.7)\n",
    "    plt.plot(plot_data.index, plot_data['Low'], 'm:', label='Low', linewidth=1, alpha=0.7)\n",
    "    \n",
    "   \n",
    "     # –®—É–º–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø–æ–∫—É–ø–∫–∏ (–±–æ–ª–µ–µ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –∏ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞)\n",
    "    buy_noised_signals = plot_data[plot_data['buy_noised'] == 1]\n",
    "    if not buy_noised_signals.empty:\n",
    "        plt.scatter(buy_noised_signals.index, buy_noised_signals['Close'], \n",
    "                   color='blue', marker='^', s=80, label='Buy noised', \n",
    "                   zorder=3, alpha=0.6, edgecolors='darkgreen', linewidth=0.5)\n",
    "        \n",
    "    # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø–æ–∫—É–ø–∫–∏\n",
    "    buy_main_signals = plot_data[plot_data['buy'] == 1]\n",
    "    if not buy_main_signals.empty:\n",
    "        plt.scatter(buy_main_signals.index, buy_main_signals['Close'], \n",
    "                   color='lightgreen', marker='^', s=80, label='Buy main', \n",
    "                   zorder=3, alpha=0.6, edgecolors='darkgreen', linewidth=0.5)\n",
    "    \n",
    "    # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø—Ä–æ–¥–∞–∂–∏\n",
    "    sell_noised_signals = plot_data[plot_data['sell'] == 1]\n",
    "    if not sell_noised_signals.empty:\n",
    "        plt.scatter(sell_noised_signals.index, sell_noised_signals['Close'], \n",
    "                   color='lightcoral', marker='v', s=80, label='Sell main', \n",
    "                   zorder=3, alpha=0.6, edgecolors='darkred', linewidth=0.5)\n",
    "    \n",
    "    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø–æ–∫—É–ø–∫–∏ (–±–æ–ª–µ–µ —è—Ä–∫–∏–µ –∏ –∫—Ä—É–ø–Ω—ã–µ)\n",
    "    buy_signals = plot_data[plot_data['buy_strong'] == 1]\n",
    "    if not buy_signals.empty:\n",
    "        plt.scatter(buy_signals.index, buy_signals['Close'], \n",
    "                   color='green', marker='^', s=20, label='Buy Strong', zorder=5)\n",
    "    \n",
    "    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –ø—Ä–æ–¥–∞–∂–∏ (–±–æ–ª–µ–µ —è—Ä–∫–∏–µ –∏ –∫—Ä—É–ø–Ω—ã–µ)\n",
    "    sell_signals = plot_data[plot_data['sell_strong'] == 1]\n",
    "    if not sell_signals.empty:\n",
    "        plt.scatter(sell_signals.index, sell_signals['Close'], \n",
    "                   color='red', marker='v', s=20, label='Sell Strong', zorder=5)\n",
    "    \n",
    "    plt.title('OHLC Prices with Buy/Sell Signals')\n",
    "    plt.xlabel('Candles')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5aee6-96a5-4861-a044-3720330f7030",
   "metadata": {},
   "source": [
    "# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4230d-3378-4e13-922e-a37c8c09dba7",
   "metadata": {},
   "source": [
    "## plot_corr_by_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9a3ab-4b93-49f5-8bc2-edf1d6874367",
   "metadata": {},
   "source": [
    "**plot_corr_by_distance** –°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–µ–¥–Ω–µ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–ø–æ –º–æ–¥—É–ª—é) –º–µ–∂–¥—É target –∏ –≤—Å–µ–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.\n",
    "- –ø–æ –æ—Å–∏ **y** —É–∫–∞–∑–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π **target** –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "- –ø–æ –æ—Å–∏ **x** –æ—Ç–ª–æ–∂–µ–Ω–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ç–µ–∫—É—â–µ–π –∑–∞–∫—Ä—ã—Ç–æ–π —Å–≤–µ—á–∏ –¥–æ —Å–≤–µ—á–µ–π –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª –ø—Ä–æ–≤–µ–¥–µ–Ω —Ä–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b3f3367-3f0b-49ad-ad4c-2f0a9190023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_by_distance(df, target='buy', pattern=r'_(\\d+)$', min_corr=0.01):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–µ–¥–Ω–µ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–ø–æ –º–æ–¥—É–ª—é) –º–µ–∂–¥—É target –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏,\n",
    "    –≥–¥–µ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞ –µ—Å—Ç—å —á–∏—Å–ª–æ (—É–¥–∞–ª–µ–Ω–∏–µ –æ—Ç —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã).\n",
    "    –í —Ä–∞—Å—á–µ—Ç –±–µ—Ä—É—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å |corr| > min_corr.\n",
    "    \"\"\"\n",
    "    corr = df.corr(numeric_only=True)[target].drop(target).abs()\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª–∞–±—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π\n",
    "    corr = corr[corr > min_corr]\n",
    "\n",
    "    distance_corrs = {}\n",
    "    for col, val in corr.items():\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            dist = int(match.group(1))\n",
    "            distance_corrs.setdefault(dist, []).append(val)\n",
    "\n",
    "    avg_corr = {dist: np.mean(vals) for dist, vals in distance_corrs.items()}\n",
    "\n",
    "    distances = sorted(avg_corr.keys())\n",
    "    values = [avg_corr[d] for d in distances]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(distances, values, marker='o')\n",
    "    plt.title('–ì—Ä–∞—Ñ–∏–∫ —É–≥–∞—Å–∞–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏')\n",
    "    plt.xlabel('–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏')\n",
    "    plt.ylabel('–°—Ä–µ–¥–Ω—è—è |corr|')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbec6c-02bf-4384-aacb-73859001c9a9",
   "metadata": {},
   "source": [
    "## plot_correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221dbb5-f7aa-44ef-bce7-70b752d5e82a",
   "metadata": {},
   "source": [
    "**plot_correlation_matrix** –°—Ç—Ä–æ–∏—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "\n",
    "–í—Ö–æ–¥:\n",
    "- df —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "- drop_columns –±–∞–∑–æ–≤—ã–µ/–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ —Ç—Ä–µ–±—É—é—â–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è\n",
    "- top_n - —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n",
    "- target - —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a18d2b6f-6435-4584-adfa-87d5a2b4b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df, target=None, drop_columns=['Data', 'High', 'Low', 'Close', 'Open', 'Volume'], top_n=30):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è —Ç–æ–ø-N –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–∞–∏–±–æ–ª–µ–µ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "        target: –∏–º—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–µ—Å–ª–∏ None - –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏)\n",
    "        drop_columns: –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ –∞–Ω–∞–ª–∏–∑–∞\n",
    "        top_n: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "        data = df.drop(drop_columns, axis=1, errors='ignore')\n",
    "        \n",
    "        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è - –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-N –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å –Ω–µ–π\n",
    "        if target is not None and target in data.columns:\n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "            target_corr = data.corr()[target].abs().sort_values(ascending=False)\n",
    "            \n",
    "            # –ë–µ—Ä–µ–º —Ç–æ–ø-N –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤–∫–ª—é—á–∞—è —Å–∞–º—É —Ü–µ–ª–µ–≤—É—é)\n",
    "            top_features = target_corr.head(top_n).index.tolist()\n",
    "            \n",
    "            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –µ—Å—Ç—å –≤ —Å–ø–∏—Å–∫–µ\n",
    "            if target not in top_features:\n",
    "                top_features.append(target)\n",
    "                \n",
    "            corr_matrix = data[top_features].corr()\n",
    "            \n",
    "        else:\n",
    "            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ - –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "            corr_matrix = data.corr()\n",
    "            \n",
    "            # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ - –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–æ–ø-N\n",
    "            if len(corr_matrix) > top_n:\n",
    "                mean_abs_corr = corr_matrix.abs().mean().sort_values(ascending=False)\n",
    "                top_features = mean_abs_corr.head(top_n).index\n",
    "                corr_matrix = corr_matrix.loc[top_features, top_features]\n",
    "        \n",
    "        num_features = len(corr_matrix)\n",
    "        \n",
    "        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "        if num_features <= 15:\n",
    "            figsize = (10, 8)\n",
    "            font_scale = 1.2\n",
    "            annot = True\n",
    "            label_size = 10\n",
    "        elif num_features <= 30:\n",
    "            figsize = (16, 14)\n",
    "            font_scale = 1.0\n",
    "            annot = False\n",
    "            label_size = 9\n",
    "        else:\n",
    "            figsize = (20, 18)\n",
    "            font_scale = 0.8\n",
    "            annot = False\n",
    "            label_size = 8\n",
    "            plt.rcParams['xtick.major.pad'] = 0.5\n",
    "            plt.rcParams['ytick.major.pad'] = 0.5\n",
    "        \n",
    "        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è\n",
    "        sns.set(font_scale=font_scale)\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã\n",
    "        heatmap = sns.heatmap(\n",
    "            corr_matrix,\n",
    "            cmap='coolwarm',\n",
    "            annot=annot,\n",
    "            fmt=\".2f\",\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.7},\n",
    "            mask=np.triu(np.ones_like(corr_matrix, dtype=bool)),\n",
    "            annot_kws={\"size\": 8} if annot else None\n",
    "        )\n",
    "        \n",
    "        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–ø–∏—Å–µ–π –æ—Å–µ–π\n",
    "        heatmap.set_xticklabels(\n",
    "            heatmap.get_xticklabels(),\n",
    "            rotation=45,\n",
    "            ha='right',\n",
    "            fontsize=label_size\n",
    "        )\n",
    "        heatmap.set_yticklabels(\n",
    "            heatmap.get_yticklabels(),\n",
    "            rotation=0,\n",
    "            fontsize=label_size\n",
    "        )\n",
    "        \n",
    "        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫\n",
    "        if target is not None and target in data.columns:\n",
    "            title = f'–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (—Ç–æ–ø-{num_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å \"{target}\")'\n",
    "        else:\n",
    "            title_suffix = f' (—Ç–æ–ø-{num_features} –∏–∑ {len(data.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)' if len(data.columns) > num_features else f' ({num_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)'\n",
    "            title = f'–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞{title_suffix}'\n",
    "            \n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6be3f4-196e-4854-8d39-dd795dda6b22",
   "metadata": {},
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dc0dd-ca00-4d31-a5f7-c6ae5ec61e41",
   "metadata": {},
   "source": [
    "**plot_price_with_indicators** –°—Ç—Ä–æ–∏—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫ —Ü–µ–Ω—ã –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ - –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã.\n",
    "\n",
    "–ù–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞–µ—Ç—Å—è:\n",
    "- df —Å –∫–æ–ª–æ–Ω–∫–æ–π —Ü–µ–Ω—ã **Close**\n",
    "- –∏—Å—Å–ª–µ–¥—É–µ–º—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –≥—Ä–∞—Ñ–∏–∫–∞ - **start / end**\n",
    "- –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "- —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ **indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6adf2938-6d66-4dca-b62e-491b989f54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_with_indicators(df, indicators, start=-400, end=-200, colors=None, title=None):\n",
    "    \"\"\"\n",
    "    df          - DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ Close –∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏\n",
    "    indicators  - —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    start, end  - –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ä–µ–∑–∞ df\n",
    "    colors      - —Å–ø–∏—Å–æ–∫ —Ü–≤–µ—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    title       - –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥—Ä–∞—Ñ–∏–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    \"\"\"\n",
    "    df_slice = df.iloc[start:end]\n",
    "    \n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(10, 6), facecolor='#f8f9fa')\n",
    "    \n",
    "    # —Ü–µ–Ω–∞ - –æ—Å–Ω–æ–≤–Ω–∞—è –ª–∏–Ω–∏—è (–∂–∏—Ä–Ω–∞—è –∏ —á–µ—Ç–∫–∞—è)\n",
    "    plt.plot(df_slice['Close'], label='Close', color='#2c3e50', linewidth=2.5, alpha=0.9)\n",
    "    plt.ylabel('Close Price', fontsize=12)\n",
    "    plt.xlabel('Minutes', fontsize=12)\n",
    "    \n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–æ–Ω–∞ –æ–±–ª–∞—Å—Ç–∏ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('#f0f3f5')\n",
    "    \n",
    "    # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –≤—Ç–æ—Ä–æ–º axes\n",
    "    ax2 = plt.twinx()\n",
    "    ax2.set_ylabel('Indicators', fontsize=12)\n",
    "    ax2.set_facecolor('#f0f3f5')\n",
    "    \n",
    "    if colors is None:\n",
    "        # –ü—Ä–∏–≥–ª—É—à–µ–Ω–Ω—ã–µ —Ü–≤–µ—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤\n",
    "        colors = ['#e74c3c', '#3498db', '#27ae60', '#f39c12', '#8e44ad', \n",
    "                 '#16a085', '#d35400', '#2c3e50', '#7f8c8d', '#9b59b6']\n",
    "    \n",
    "    # –≠–ª–µ–≥–∞–Ω—Ç–Ω—ã–µ —Å—Ç–∏–ª–∏ –ª–∏–Ω–∏–π\n",
    "    line_styles = ['--', '-.', ':', '--', '-.', ':']\n",
    "    \n",
    "    for i, ind in enumerate(indicators):\n",
    "        # –®—Ç—Ä–∏—Ö–æ–≤—ã–µ –ª–∏–Ω–∏–∏ —Å —Ö–æ—Ä–æ—à–µ–π –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é\n",
    "        ax2.plot(df_slice[ind], label=ind, \n",
    "                color=colors[i % len(colors)], \n",
    "                linestyle=line_styles[i % len(line_styles)],\n",
    "                linewidth=1.8, \n",
    "                alpha=0.7)  # –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å\n",
    "    \n",
    "    # –ª–µ–≥–µ–Ω–¥–∞\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    plt.legend(lines1 + lines2, labels1 + labels2, loc='upper left',\n",
    "              frameon=True, fancybox=True, shadow=True, fontsize=10)\n",
    "    \n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Ç–∫–∏\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)  # –æ—á–µ–Ω—å –ª–µ–≥–∫–∞—è —Å–µ—Ç–∫–∞\n",
    "    ax2.grid(False)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29007fa-9678-42ae-9e1b-58cf13d9ecae",
   "metadata": {},
   "source": [
    "# –†–∞—Å—á—ë—Ç –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ Mutual Information (–¥–æ –º–æ–¥–µ–ª–µ–π)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce45fbb-c76a-4f16-91bc-98891241561d",
   "metadata": {},
   "source": [
    "**mutual_info_classif** –≤—ã—á–∏—Å–ª—è–µ—Ç –≤–∑–∞–∏–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ–∂–¥—É –∫–∞–∂–¥—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.\\\n",
    "\n",
    "–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
    "- X_train ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "- y_train ‚Äî —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
    "- top_n ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "- random_state ‚Äî seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "\n",
    "–ü—Ä–æ—Ü–µ—Å—Å —Ä–∞–±–æ—Ç—ã:\n",
    "- –í—ã—á–∏—Å–ª—è–µ—Ç Mutual Information –º–µ–∂–¥—É –∫–∞–∂–¥—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "- –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–∞–∂–Ω–æ—Å—Ç–∏\n",
    "- –í—ã–≤–æ–¥–∏—Ç —Ç–∞–±–ª–∏—Ü—É —Ç–æ–ø-N –Ω–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "- –°—Ç—Ä–æ–∏—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –±–∞—Ä—á–∞—Ä—Ç –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "\n",
    "–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:\n",
    "- –†–∞–±–æ—Ç–∞–µ—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –∏ —á–∏—Å–ª–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "- –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: –ú–æ–∂–µ—Ç –≤—ã—è–≤–∏—Ç—å —Å–ª–æ–∂–Ω—ã–µ —Å–≤—è–∑–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –ª–∏–Ω–µ–π–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ad93966-6310-45e9-bc9a-096832e96529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_mutual_info(X_train, y_train, top_n=20, random_state=3):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—á—ë—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ Mutual Information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(f\"‚ÑπÔ∏è Calculating Mutual Information for {X_train.shape[1]} features...\")\n",
    "\n",
    "        # 1. –†–∞—Å—á—ë—Ç MI\n",
    "        mi_scores = mutual_info_classif(X_train, y_train, random_state=random_state)\n",
    "        mi_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'MI_Score': mi_scores\n",
    "        }).sort_values('MI_Score', ascending=False)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"‚úÖ MI calculation completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # 2. –¢–∞–±–ª–∏—Ü–∞ —Ç–æ–ø-N\n",
    "        print(f\"\\nüîç Top {top_n} Features by Mutual Information:\")\n",
    "        print(mi_df.head(top_n).to_markdown(index=False, floatfmt=\".4f\"))\n",
    "\n",
    "        # 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        plt.barh(mi_df['Feature'].head(top_n)[::-1], \n",
    "                 mi_df['MI_Score'].head(top_n)[::-1], \n",
    "                 color='skyblue')\n",
    "        plt.xlabel('Mutual Information Score')\n",
    "        plt.title(f'Top {top_n} Features by Mutual Information')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á—ë—Ç–µ Mutual Information: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb430a-79b8-4bcb-9419-6110bcb579f8",
   "metadata": {},
   "source": [
    "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –≤–Ω—É—Ç—Ä–∏ –≤—ã–±–æ—Ä–æ–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901c7f9-a77b-4ce1-8af3-371104dd0019",
   "metadata": {},
   "source": [
    "## show_class_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee96d56-f787-4cd8-b5cc-14e526ee26a3",
   "metadata": {},
   "source": [
    "**show_class_balance** –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ –≤—ã–±–æ—Ä–∫–∞–º\n",
    "\n",
    "–í—Ö–æ–¥:\n",
    "- y: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "- y_train: –æ–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
    "- y_valid: –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
    "- y_test: —Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
    "\n",
    "–í—ã—Ö–æ–¥:\n",
    "- –¢–∞–±–ª–∏—Ü–∞ —Å –¥–æ–ª—è–º–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ –∫–∞–∂–¥–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "- –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "- –í–∏–∑—É–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–ß—Ç–æ –¥–µ–ª–∞–µ—Ç: –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤ –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ –≤—ã–±–æ—Ä–∫–∞–º–∏ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "272fcf1c-ed0d-4c0c-a2ec-c08a0685eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_class_balance(y, y_train, y_valid, y_test):\n",
    "    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—É\n",
    "    balance_df = pd.DataFrame({\n",
    "        '–í–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç': y.value_counts(normalize=True).round(3),\n",
    "        '–û–±—É—á–∞—é—â–∞—è': y_train.value_counts(normalize=True).round(3),\n",
    "        '–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è': y_valid.value_counts(normalize=True).round(3),\n",
    "        '–¢–µ—Å—Ç–æ–≤–∞—è': y_test.value_counts(normalize=True).round(3)\n",
    "    }).fillna(0)  # –Ω–∞ —Å–ª—É—á–∞–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤\n",
    "    \n",
    "    # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –≤ —Å—Ç–∏–ª–µ \"plain\"\n",
    "    print(\"üìä –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (–¥–æ–ª–∏):\")\n",
    "    print(\n",
    "        balance_df.to_markdown(\n",
    "            tablefmt=\"simple\",  # –ß–∏—Å—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ª–∏–Ω–∏–π\n",
    "            stralign=\"center\",  # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ —Ü–µ–Ω—Ç—Ä—É\n",
    "            floatfmt=\".3f\"       # –§–æ—Ä–º–∞—Ç —á–∏—Å–µ–ª\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    balance_df.plot(kind='bar', width=0.8, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ –≤—ã–±–æ—Ä–∫–∞–º', pad=20)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel('–î–æ–ª—è –∫–ª–∞—Å—Å–∞')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.legend(framealpha=0.9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc7cfd-10ae-436b-a72f-15074f380bd8",
   "metadata": {},
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792b7fa-9be8-4b5b-83a3-765d41bc6c0b",
   "metadata": {},
   "source": [
    "## evaluate_model_with_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91837d42-ecc5-43db-aa2f-cc2979bd4e68",
   "metadata": {},
   "source": [
    "**evaluate_model_with_threshold** –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –ø–æ–¥–±–æ—Ä–æ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "–í—Ö–æ–¥:\n",
    "- model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "- X_train, y_train: –æ–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
    "- X_valid, y_valid: –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
    "- X_test, y_test: —Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "\n",
    "–í—ã—Ö–æ–¥:\n",
    "- –°–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—å—é, –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:\n",
    "- –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "- –ú–µ—Ç—Ä–∏–∫–∏ (F1, Precision, Recall, ROC AUC) –¥–ª—è –≤—Å–µ—Ö –≤—ã–±–æ—Ä–æ–∫\n",
    "- –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "- –°–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "516b885e-bf5b-4f9e-bce8-0b962dee603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_threshold(model, X_train, y_train, X_valid, y_valid, X_test=None, y_test=None):\n",
    "    \"\"\"\n",
    "    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n",
    "    {\n",
    "        'model': model,  # –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "        'metrics': {\n",
    "            'train': {–º–µ—Ç—Ä–∏–∫–∏},\n",
    "            'valid': {–º–µ—Ç—Ä–∏–∫–∏},\n",
    "            'test': {–º–µ—Ç—Ä–∏–∫–∏} (–µ—Å–ª–∏ –µ—Å—Ç—å),\n",
    "            'optimal_threshold': float\n",
    "        },\n",
    "        'features': list,  # —Å–ø–∏—Å–æ–∫ —Ñ–∏—á–µ–π\n",
    "        'timestamp': str   # –≤—Ä–µ–º—è –æ—Ü–µ–Ω–∫–∏\n",
    "    }\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # 1. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_valid_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 2. –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –ø–æ—Ä–æ–≥–æ–≤\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    \n",
    "    # 3. –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è F1 –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–∞—Ö\n",
    "    def find_best_threshold(y_true, y_proba, thresholds):\n",
    "        f1_scores = []\n",
    "        for t in thresholds:\n",
    "            y_pred = (y_proba >= t).astype(int)\n",
    "            f1_scores.append(f1_score(y_true, y_pred, zero_division=0))\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        return thresholds[best_idx], f1_scores\n",
    "    \n",
    "    # 4. –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è train –∏ valid\n",
    "    train_best_threshold, train_f1_scores = find_best_threshold(y_train, y_train_proba, thresholds)\n",
    "    valid_best_threshold, valid_f1_scores = find_best_threshold(y_valid, y_valid_proba, thresholds)\n",
    "    \n",
    "    # 5. –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥\n",
    "    optimal_threshold = np.mean([train_best_threshold, valid_best_threshold])\n",
    "    \n",
    "    # 6. –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏\n",
    "    train_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'f1_scores': train_f1_scores,\n",
    "        'precision': [precision_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'recall': [recall_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_train_proba,\n",
    "        'max_f1_threshold': train_best_threshold,\n",
    "        'roc_auc': roc_auc_score(y_train, y_train_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC\n",
    "    }\n",
    "    \n",
    "    valid_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'f1_scores': valid_f1_scores,\n",
    "        'precision': [precision_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'recall': [recall_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_valid_proba,\n",
    "        'max_f1_threshold': valid_best_threshold,\n",
    "        'roc_auc': roc_auc_score(y_valid, y_valid_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC\n",
    "    }\n",
    "    \n",
    "    # 7. –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(f\"üéØ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥ –ø–æ F1 (Train): {train_best_threshold:.4f}\")\n",
    "    print(f\"üéØ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥ –ø–æ F1 (Valid): {valid_best_threshold:.4f}\")\n",
    "    print(f\"‚úÖ –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.4f}\")\n",
    "    print(f\"\\nüìä ROC AUC Scores:\")\n",
    "    print(f\"‚úÖ Train ROC AUC: {train_metrics['roc_auc']:.4f}\")\n",
    "    print(f\"‚úÖ Valid ROC AUC: {valid_metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # 8. –°—á–∏—Ç–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º\n",
    "    def calculate_final_metrics(y_true, y_proba, threshold, set_name):\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        metrics = {\n",
    "            'F1': f1_score(y_true, y_pred, zero_division=0),\n",
    "            'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'ROC_AUC': roc_auc_score(y_true, y_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC\n",
    "        }\n",
    "        print(f\"\\nüìä {set_name} set (Threshold = {threshold:.4f}):\")\n",
    "        print(f\"‚úÖ F1: {metrics['F1']:.4f}\")\n",
    "        print(f\"‚úÖ Precision: {metrics['Precision']:.4f}\")\n",
    "        print(f\"‚úÖ Recall: {metrics['Recall']:.4f}\")\n",
    "        print(f\"‚úÖ ROC AUC: {metrics['ROC_AUC']:.4f}\")\n",
    "        return metrics\n",
    "    \n",
    "    train_metrics['final_metrics'] = calculate_final_metrics(y_train, y_train_proba, optimal_threshold, \"Train\")\n",
    "    valid_metrics['final_metrics'] = calculate_final_metrics(y_valid, y_valid_proba, optimal_threshold, \"Valid\")\n",
    "    \n",
    "    results = {\n",
    "        'train': train_metrics,\n",
    "        'valid': valid_metrics,\n",
    "        'optimal_threshold': optimal_threshold\n",
    "    }\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        test_metrics = {\n",
    "            'thresholds': thresholds,\n",
    "            'f1_scores': [f1_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'precision': [precision_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'recall': [recall_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'y_proba': y_test_proba,\n",
    "            'roc_auc': roc_auc_score(y_test, y_test_proba)  # –î–æ–±–∞–≤–ª–µ–Ω–æ ROC AUC\n",
    "        }\n",
    "        test_metrics['final_metrics'] = calculate_final_metrics(\n",
    "            y_test, y_test_proba, optimal_threshold, \"Test\"\n",
    "        )\n",
    "        results['test'] = test_metrics\n",
    "    \n",
    "    # 9. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # 1. –ö—Ä–∏–≤—ã–µ –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(train_best_threshold, color='b', linestyle=':', label=f'Train Max F1: {train_best_threshold:.3f}')\n",
    "    plt.title('Train Selection')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 2. –ö—Ä–∏–≤—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(valid_best_threshold, color='orange', linestyle=':', label=f'Valid Max F1: {valid_best_threshold:.3f}')\n",
    "    plt.title('Test Set')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ F1-–∫—Ä–∏–≤—ã—Ö —Å –Ω–æ–≤—ã–º –ø–æ—Ä–æ–≥–æ–º\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='Train F1', color='blue')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='Valid F1', color='orange')\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª–µ–Ω–∞ —Ç—Ä–µ—Ç—å—è –ª–∏–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å\n",
    "    if X_test is not None and y_test is not None:\n",
    "        plt.plot(test_metrics['thresholds'], test_metrics['f1_scores'], label='Test F1', color='green')\n",
    "    \n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(train_best_threshold, color='b', linestyle=':', alpha=0.5)\n",
    "    plt.axvline(valid_best_threshold, color='orange', linestyle=':', alpha=0.5)\n",
    "    plt.title('F1 Comparison with Optimal Threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 10. –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ (–¥–æ–±–∞–≤–ª—è–µ–º ROC AUC)\n",
    "    final_table = [\n",
    "        [\"Dataset\", \"Threshold Type\"] + list(train_metrics['final_metrics'].keys()),\n",
    "        [\"Train\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(train_metrics['final_metrics'].values()),\n",
    "        [\"Test\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(valid_metrics['final_metrics'].values())\n",
    "    ]\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        final_table.append(\n",
    "            [\"Test\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(results['test']['final_metrics'].values())\n",
    "        )\n",
    "    \n",
    "    # print(\"\\n–ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ —Å—Ä–µ–¥–Ω–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º:\")\n",
    "    # print(tabulate(final_table, headers=\"firstrow\", floatfmt=\".4f\", tablefmt=\"grid\"))\n",
    "\n",
    "     # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\n",
    "    model_package = {\n",
    "        'model': model,\n",
    "        'metrics': {\n",
    "            'train': train_metrics['final_metrics'],\n",
    "            'valid': valid_metrics['final_metrics'],\n",
    "            'optimal_threshold': optimal_threshold\n",
    "        },\n",
    "        'features': list(X_train.columns),\n",
    "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        model_package['metrics']['test'] = results['test']['final_metrics']\n",
    "    \n",
    "    return model_package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd9cc88-f7ac-473f-89c5-a92960a8c049",
   "metadata": {},
   "source": [
    "# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2958bb-0ad8-4fe7-9823-909848f4c920",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95e1ae-6bc0-4600-9caa-12549f310c3d",
   "metadata": {},
   "source": [
    "### explain_model_shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e83025-79e3-45b9-9b94-04376c5ef512",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è **explain_model_shap**: \n",
    "- –í—ã—á–∏—Å–ª—è–µ—Ç SHAP-–∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\n",
    "- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "- –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–ø-N –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
    "- X_train ‚Äî –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "- model ‚Äî –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (RandomForest, XGBoost, LogisticRegression –∏ –¥—Ä.)\n",
    "- sample_size ‚Äî —Ä–∞–∑–º–µ—Ä –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2000)\n",
    "- top_n ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "- n_jobs ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "\n",
    "–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
    "- DataFrame —Å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏\n",
    "- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "\n",
    "–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–∞:\n",
    "- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏ (TreeExplainer, LinearExplainer)\n",
    "- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "- –ê–Ω–∞–ª–∏–∑ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–ª–∏—è–Ω–∏—è (Positive/Negative)\n",
    "- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å feature_importances_ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:\n",
    "- –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ %\n",
    "- –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "- –ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f6f1aa7-ff27-4c41-bbe2-dfa01c8734c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_shap(X_train, model, sample_size=2000, top_n=20, n_jobs = -1):\n",
    "    \"\"\"\n",
    "    –û–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç —Ä–∞—Å—á–µ—Ç SHAP-–≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        –î–∞—Ç–∞—Ñ—Ä–µ–π–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    model : sklearn/xgboost –º–æ–¥–µ–ª—å\n",
    "        –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (RandomForest, LogisticRegression, XGB –∏ –¥—Ä.)\n",
    "    sample_size : int\n",
    "        –†–∞–∑–º–µ—Ä —Å–ª—É—á–∞–π–Ω–æ–π –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏\n",
    "    top_n : int\n",
    "        –ö–æ–ª-–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_start_time = time.time()\n",
    "        model_type = type(model).__name__\n",
    "        \n",
    "        print(f\"‚ÑπÔ∏è Model type: {model_type}\")\n",
    "        print(f\"‚ÑπÔ∏è Number of classes: {getattr(model, 'n_classes_', 'unknown')}\")\n",
    "        \n",
    "        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Explainer\n",
    "        print(\"üîÑ Initializing SHAP explainer...\")\n",
    "        explainer_start = time.time()\n",
    "        if model_type in ['RandomForestClassifier', 'RandomForestRegressor', \n",
    "                          'XGBClassifier', 'XGBRegressor', \n",
    "                          'LGBMClassifier', 'LGBMRegressor']:\n",
    "            explainer = shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\")\n",
    "        elif model_type in ['LogisticRegression', 'LinearRegression']:\n",
    "            explainer = shap.LinearExplainer(model, X_train)\n",
    "        else:\n",
    "            explainer = shap.Explainer(model, X_train)\n",
    "        explainer_time = time.time() - explainer_start\n",
    "        print(f\"‚úÖ SHAP explainer initialized in {timedelta(seconds=explainer_time)}\")\n",
    "        \n",
    "        # 2. –ü–æ–¥–≤—ã–±–æ—Ä–∫–∞\n",
    "        sample_size = min(sample_size, len(X_train))\n",
    "        sample_idx = np.random.choice(X_train.index, size=sample_size, replace=False)\n",
    "        X_sample = X_train.loc[sample_idx]\n",
    "\n",
    "        print(f\"\\nüîÑ Calculating SHAP values for {sample_size} samples...\")\n",
    "        shap_start = time.time()\n",
    "\n",
    "        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
    "        n_jobs = n_jobs\n",
    "        n_chunks = 4 * (os.cpu_count() or 1)\n",
    "\n",
    "        def calc_chunk(chunk):\n",
    "            return explainer.shap_values(chunk, approximate=True, check_additivity=False)\n",
    "\n",
    "        chunks = np.array_split(X_sample, n_chunks)\n",
    "        results = Parallel(n_jobs=n_jobs)(delayed(calc_chunk)(chunk) for chunk in chunks)\n",
    "\n",
    "        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "        if isinstance(results[0], list):\n",
    "            shap_values = [np.concatenate([r[i] for r in results]) for i in range(len(results[0]))]\n",
    "        else:\n",
    "            shap_values = np.concatenate(results)\n",
    "\n",
    "        shap_time = time.time() - shap_start\n",
    "        print(f\"‚úÖ SHAP values calculated in {timedelta(seconds=shap_time)}\")\n",
    "        print(f\"‚è± Average time per sample: {shap_time/sample_size:.4f} seconds\")\n",
    "\n",
    "        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ SHAP\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1] if len(shap_values) == 2 else np.mean(shap_values, axis=0)\n",
    "        elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "            shap_values = shap_values[:, :, 1]\n",
    "\n",
    "        print(f\"‚ÑπÔ∏è Processed SHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "        # 4. –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏\n",
    "        print(\"\\nüîÑ Calculating feature importance...\")\n",
    "        analysis_start = time.time()\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'SHAP_Importance': np.abs(shap_values).mean(axis=0),\n",
    "            'Direction': np.where(np.mean(shap_values, axis=0) > 0, 'Positive', 'Negative')\n",
    "        })\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance_df['Model_Importance'] = model.feature_importances_\n",
    "            importance_df['Model_%'] = 100 * importance_df['Model_Importance'] / importance_df['Model_Importance'].max()\n",
    "\n",
    "        importance_df['SHAP_%'] = 100 * importance_df['SHAP_Importance'] / importance_df['SHAP_Importance'].max()\n",
    "        importance_df = importance_df.sort_values('SHAP_%', ascending=False)\n",
    "        importance_df['Rank'] = range(1, len(importance_df) + 1)\n",
    "        importance_df['Cumulative_SHAP_%'] = importance_df['SHAP_%'].cumsum()\n",
    "        analysis_time = time.time() - analysis_start\n",
    "        print(f\"‚úÖ Feature analysis completed in {timedelta(seconds=analysis_time)}\")\n",
    "\n",
    "        # 5. –¢–∞–±–ª–∏—Ü–∞\n",
    "        print(\"\\nüîç Top Features by SHAP Importance:\")\n",
    "        display_cols = ['Rank', 'Feature', 'SHAP_%', 'Direction']\n",
    "        if 'Model_%' in importance_df.columns:\n",
    "            display_cols.append('Model_%')\n",
    "        print(importance_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=\".1f\"))\n",
    "\n",
    "        print(\"\\nüìä Key Metrics:\")\n",
    "        print(f\"‚Ä¢ Top-5 features explain: {importance_df['Cumulative_SHAP_%'].iloc[4]:.1f}%\")\n",
    "        pos_count = (importance_df['Direction'] == 'Positive').sum()\n",
    "        neg_count = (importance_df['Direction'] == 'Negative').sum()\n",
    "        print(f\"‚Ä¢ Positive/Negative: {pos_count}/{neg_count}\")\n",
    "\n",
    "        # 6. –ü—Ä–æ—Å—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        colors = importance_df['Direction'].head(top_n).map({'Positive': 'tomato', 'Negative': 'dodgerblue'})\n",
    "        plt.barh(importance_df['Feature'].head(top_n)[::-1], \n",
    "                 importance_df['SHAP_%'].head(top_n)[::-1],\n",
    "                 color=colors[::-1])\n",
    "        plt.title(f'Top {top_n} Features by SHAP')\n",
    "        plt.xlabel('Relative SHAP Importance (%)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 7. –û–±—â–µ–µ –≤—Ä–µ–º—è\n",
    "        total_time = time.time() - total_start_time\n",
    "        print(f\"\\n‚è± Total execution time: {timedelta(seconds=total_time)}\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Time breakdown:\")\n",
    "        print(f\"- Explainer init: {timedelta(seconds=explainer_time)}\")\n",
    "        print(f\"- SHAP values: {timedelta(seconds=shap_time)} ({shap_time/total_time*100:.1f}%)\")\n",
    "        print(f\"- Analysis: {timedelta(seconds=analysis_time)} ({analysis_time/total_time*100:.1f}%)\")\n",
    "\n",
    "        return importance_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "        if 'shap_values' in locals():\n",
    "            print(f\"SHAP values type: {type(shap_values)}\")\n",
    "            if hasattr(shap_values, 'shape'):\n",
    "                print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "        print(f\"X_train shape: {X_train.shape if X_train is not None else 'N/A'}\")\n",
    "        if hasattr(model, 'n_features_in_'):\n",
    "            print(f\"Model features: {model.n_features_in_}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d2d63-2ead-4130-8e19-f8d23655fbcf",
   "metadata": {},
   "source": [
    "## Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b092-0b78-45c5-accf-c1fa41b8e7dd",
   "metadata": {},
   "source": [
    "### explain_model_permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54ad36-eaca-40ce-9668-511909027006",
   "metadata": {},
   "source": [
    "**explain_model_permutation** –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é Permutation Importance\n",
    "\n",
    "–í—Ö–æ–¥:\n",
    "- X: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏\n",
    "- y: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
    "- model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (RandomForest, XGBoost –∏ –¥—Ä.)\n",
    "- scoring: –º–µ—Ç—Ä–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏ ('f1', 'accuracy', 'roc_auc')\n",
    "- n_repeats: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
    "- top_n: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "- random_state: seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "- n_jobs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–¥–µ—Ä –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "\n",
    "–í—ã—Ö–æ–¥:\n",
    "- DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature, Mean Importance, Std, Significant, Rank)\n",
    "- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ø-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8febae14-8416-4b20-ba44-9e67d46cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_permutation(X, y, model, scoring='f1', n_repeats=5, top_n=20, random_state=3, n_jobs = 4):\n",
    "    \"\"\"\n",
    "    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é Permutation Importance.\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        –ü—Ä–∏–∑–Ω–∞–∫–∏ (X_train –∏–ª–∏ X_valid)\n",
    "    y : pd.Series\n",
    "        –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
    "    model : –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "        RandomForest, LogisticRegression, XGBoost –∏ —Ç.–¥.\n",
    "    scoring : str\n",
    "        –ú–µ—Ç—Ä–∏–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'f1', 'accuracy', 'roc_auc')\n",
    "    n_repeats : int\n",
    "        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏\n",
    "    top_n : int\n",
    "        –ö–æ–ª-–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "    random_state : int\n",
    "        –°–ª—É—á–∞–π–Ω–æ–µ –∑–µ—Ä–Ω–æ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    pd.DataFrame ‚Äî —Ç–∞–±–ª–∏—Ü–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"‚ÑπÔ∏è Model type: {type(model).__name__}\")\n",
    "        print(f\"‚ÑπÔ∏è Scoring metric: {scoring}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(\"üîÑ Calculating permutation importance...\")\n",
    "        result = permutation_importance(\n",
    "            model, X, y,\n",
    "            scoring=scoring,\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"‚úÖ Completed in {timedelta(seconds=elapsed)}\")\n",
    "\n",
    "        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "        importances_df = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Mean Importance': result.importances_mean,\n",
    "            'Std': result.importances_std\n",
    "        })\n",
    "        importances_df['Significant'] = importances_df['Mean Importance'] - 2 * importances_df['Std'] > 0\n",
    "        importances_df = importances_df.sort_values(by='Mean Importance', ascending=False).reset_index(drop=True)\n",
    "        importances_df['Rank'] = importances_df.index + 1\n",
    "\n",
    "        print(\"\\nüîç Top Features by Permutation Importance:\")\n",
    "        display_cols = ['Rank', 'Feature', 'Mean Importance', 'Std', 'Significant']\n",
    "        print(importances_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=\".3f\"))\n",
    "\n",
    "        # –ü—Ä–æ—Å—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        top_features = importances_df.head(top_n)\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        bars = plt.barh(top_features['Feature'][::-1], top_features['Mean Importance'][::-1],\n",
    "                        xerr=top_features['Std'][::-1], color='mediumseagreen')\n",
    "        plt.xlabel(\"Mean Importance\")\n",
    "        plt.title(f\"Top {top_n} Features by Permutation Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return importances_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during permutation importance: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1e2d8-b399-4538-96c5-e31c23234948",
   "metadata": {},
   "source": [
    "# –°–∏–≥–Ω–∞–ª—ã –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c9837-4416-43be-80a6-11a9ae2ec468",
   "metadata": {},
   "source": [
    "**plot_predict_signals** –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç OHLC –≥—Ä–∞—Ñ–∏–∫ —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ç–æ—Ä–≥–æ–≤—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏\n",
    "\n",
    "–ê—Ä–≥—É–º–µ–Ω—Ç—ã:\n",
    "- df —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: 'Open','High','Low','Close','buy','sell'\n",
    "- y_pred: –º–∞—Å—Å–∏–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "- pred_threshold: –ø–æ—Ä–æ–≥ –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "- start_idx: –Ω–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞\n",
    "- end_idx: –∫–æ–Ω–µ—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞\n",
    "\n",
    "–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç:\n",
    "- –õ–∏–Ω–∏–∏ OHLC —Ü–µ–Ω\n",
    "- –ò—Å—Ç–∏–Ω–Ω—ã–µ buy/sell —Å–∏–≥–Ω–∞–ª—ã (–∑–µ–ª–µ–Ω—ã–µ/–∫—Ä–∞—Å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã)\n",
    "- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ buy —Å–∏–≥–Ω–∞–ª—ã –º–æ–¥–µ–ª–∏ (—Å–∏–Ω–∏–µ –º–∞—Ä–∫–µ—Ä—ã)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73cb54ac-e8c4-4965-a37d-44305cdac3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predict_signals(df, y_pred=None, pred_threshold=0.5, start_idx=200, end_idx=500):\n",
    "    \"\"\"\n",
    "    –†–∏—Å—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ OHLC —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π buy/sell —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –º–æ–¥–µ–ª–∏\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'Open','High','Low','Close','buy','sell'\n",
    "        y_pred: –º–∞—Å—Å–∏–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏–ª–∏ –±–∏–Ω–∞—Ä–Ω—ã–µ)\n",
    "        pred_threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "        start_idx: –Ω–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞\n",
    "        end_idx: –∫–æ–Ω–µ—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—á–∞—Å—Ç–∫–∞\n",
    "    \"\"\"\n",
    "    if end_idx is None:\n",
    "        end_idx = len(df)\n",
    "    \n",
    "    plot_data = df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –æ–Ω–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã\n",
    "    if y_pred is not None:\n",
    "        # –ë–∏–Ω–∞—Ä–∏–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ –ø–æ—Ä–æ–≥—É\n",
    "        y_pred_binary = (y_pred[start_idx:end_idx] >= pred_threshold).astype(int)\n",
    "        plot_data['model_buy'] = y_pred_binary\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # –†–∏—Å—É–µ–º –≤—Å–µ —Ü–µ–Ω–æ–≤—ã–µ –ª–∏–Ω–∏–∏\n",
    "    plt.plot(plot_data.index, plot_data['Close'], 'b-', label='Close', linewidth=1.5, alpha=0.8)\n",
    "    plt.plot(plot_data.index, plot_data['Open'], 'g--', label='Open', linewidth=1, alpha=0.6)\n",
    "    plt.plot(plot_data.index, plot_data['High'], 'c:', label='High', linewidth=1, alpha=0.6)\n",
    "    plt.plot(plot_data.index, plot_data['Low'], 'm:', label='Low', linewidth=1, alpha=0.6)\n",
    "    \n",
    "    # –°–∏–≥–Ω–∞–ª—ã –ø–æ–∫—É–ø–∫–∏ (–∏—Å—Ç–∏–Ω–Ω—ã–µ)\n",
    "    buy_signals = plot_data[plot_data['buy'] == 1]\n",
    "    if not buy_signals.empty:\n",
    "        plt.scatter(buy_signals.index, buy_signals['Close'], \n",
    "                   color='green', marker='^', s=120, label='True Buy', zorder=5, alpha=0.8)\n",
    "    \n",
    "    # –°–∏–≥–Ω–∞–ª—ã –ø—Ä–æ–¥–∞–∂–∏ (–∏—Å—Ç–∏–Ω–Ω—ã–µ)\n",
    "    sell_signals = plot_data[plot_data['sell'] == 1]\n",
    "    if not sell_signals.empty:\n",
    "        plt.scatter(sell_signals.index, sell_signals['Close'], \n",
    "                   color='red', marker='v', s=120, label='True Sell', zorder=5, alpha=0.8)\n",
    "    \n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã)\n",
    "    if y_pred is not None:\n",
    "        model_buy_signals = plot_data[plot_data['model_buy'] == 1]\n",
    "        if not model_buy_signals.empty:\n",
    "            plt.scatter(model_buy_signals.index, model_buy_signals['Close'], \n",
    "                       color='blue', marker='^', s=100, label=f'Model Buy (‚â•{pred_threshold})', \n",
    "                       zorder=4, alpha=0.6, edgecolors='black', linewidth=1)\n",
    "    \n",
    "    plt.title(f'OHLC Prices with Buy/Sell Signals (Threshold: {pred_threshold})')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6a0c3-57fb-4c6c-b448-066f473d38d6",
   "metadata": {},
   "source": [
    "# –ë—ç–∫—Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0be2b9-794b-4769-873f-e0b1bb3b56ed",
   "metadata": {},
   "source": [
    "**backtest_model** –ü—Ä–æ–≤–æ–¥–∏—Ç –ø–æ—à–∞–≥–æ–≤—ã–π –±—ç–∫—Ç–µ—Å—Ç —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å TP/SL –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "\n",
    "–ê—Ä–≥—É–º–µ–Ω—Ç—ã:\n",
    "- df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "- model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "- X_train: —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –¥–ª—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "- threshold: –ø–æ—Ä–æ–≥ –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤\n",
    "- tp_pct: —É—Ä–æ–≤–µ–Ω—å —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞ (%)\n",
    "- rr: —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å\n",
    "- plot: —Ñ–ª–∞–≥ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "\n",
    "–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "- –û–±—â—É—é –ø—Ä–∏–±—ã–ª—å –∏ —Å—á–µ—Ç—á–∏–∫ TP/SL —Å–¥–µ–ª–æ–∫\n",
    "- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Å–µ—Ä–∏—é —É–±—ã—Ç–∫–æ–≤\n",
    "- –ü–æ–º–µ—Å—è—á–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "- –¢–∞–±–ª–∏—Ü—É –≤—Å–µ—Ö —Å–¥–µ–ª–æ–∫\n",
    "- –ì—Ä–∞—Ñ–∏–∫–∏ –∫—Ä–∏–≤–æ–π –∫–∞–ø–∏—Ç–∞–ª–∞ –∏ –º–µ—Å—è—á–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba07626b-a20e-48f7-9657-e64bfca1f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_model(df, model, X_train, threshold=0.5, tp_pct=0.04, rr=2.0, plot=True):\n",
    "    \"\"\"\n",
    "    –ü–æ—à–∞–≥–æ–≤—ã–π –±—ç–∫—Ç–µ—Å—Ç —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å TP –∏ SL.\n",
    "    –ü–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è —Å–¥–µ–ª–∫–∏ —Å–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—á–∏.\n",
    "    –†–µ–∑—É–ª—å—Ç–∞—Ç: –º–µ—Ç—Ä–∏–∫–∏, —Ç–∞–±–ª–∏—Ü–∞ —Å–¥–µ–ª–æ–∫, –ø–æ–º–µ—Å—è—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∫—Ä–∏–≤–∞—è –∫–∞–ø–∏—Ç–∞–ª–∞.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞\n",
    "        model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "        X_train: —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è feature_cols)\n",
    "        threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –≤—Ö–æ–¥–∞ –≤ —Å–¥–µ–ª–∫—É\n",
    "        tp_pct: —É—Ä–æ–≤–µ–Ω—å —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö\n",
    "        rr: risk-reward ratio\n",
    "        plot: —Å—Ç—Ä–æ–∏—Ç—å –ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏\n",
    "    \"\"\"\n",
    "\n",
    "    # –ë–∞–∑–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–∏—Å–∫–ª—é—á–∞–µ–º —Ç–µ, —á—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –≤ df –Ω–æ –Ω–µ –≤ —Ñ–∏—á–∞—Ö)\n",
    "    base_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'buy', 'sell', \n",
    "                 'buy_strong', 'sell_strong', 'buy_noised', 'sell_noised']\n",
    "    \n",
    "    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –±–µ—Ä—É—Ç—Å—è –∏–∑ X_train.columns\n",
    "    feature_cols = [col for col in X_train.columns if col in df.columns]\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ñ–∏—á–∏ –µ—Å—Ç—å –≤ df\n",
    "    missing_features = set(X_train.columns) - set(df.columns)\n",
    "    if missing_features:\n",
    "        print(f\"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∏—á–∏ –≤ df: {missing_features}\")\n",
    "        print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∏—á–∏: {feature_cols}\")\n",
    "\n",
    "    # –î–ª—è SL\n",
    "    sl_pct = tp_pct / rr\n",
    "\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∏—á–∏)\n",
    "    if feature_cols:\n",
    "        preds = model.predict_proba(df[feature_cols])[:, 1]\n",
    "        df = df.copy()\n",
    "        df['pred'] = preds\n",
    "    else:\n",
    "        print(\"‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∏—á –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è!\")\n",
    "        return None\n",
    "\n",
    "    all_trades = []\n",
    "    current_trade = None\n",
    "    i = 0\n",
    "    n = len(df)\n",
    "    balance = [0]  # –∫—Ä–∏–≤–∞—è –∫–∞–ø–∏—Ç–∞–ª–∞\n",
    "\n",
    "    while i < n:\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–¥–µ–ª–∫–∏ ‚Äî –∏—â–µ–º –≤—Ö–æ–¥\n",
    "        if current_trade is None:\n",
    "            if row['pred'] >= threshold:\n",
    "                entry_price = row['Close']\n",
    "                tp_price = entry_price * (1 + tp_pct)\n",
    "                sl_price = entry_price * (1 - sl_pct)\n",
    "\n",
    "                current_trade = {\n",
    "                    'entry_date': row['Date'],\n",
    "                    'entry_price': entry_price,\n",
    "                    'tp_price': tp_price,\n",
    "                    'sl_price': sl_price\n",
    "                }\n",
    "        else:\n",
    "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞\n",
    "            if row['Low'] <= current_trade['sl_price']:\n",
    "                current_trade['exit_date'] = row['Date']\n",
    "                current_trade['outcome'] = 'SL'\n",
    "                current_trade['profit_pct'] = -sl_pct\n",
    "                all_trades.append(current_trade)\n",
    "                balance.append(balance[-1] - sl_pct)\n",
    "                current_trade = None\n",
    "                i += 1  # –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—á–∏\n",
    "                continue\n",
    "\n",
    "            if row['High'] >= current_trade['tp_price']:\n",
    "                current_trade['exit_date'] = row['Date']\n",
    "                current_trade['outcome'] = 'TP'\n",
    "                current_trade['profit_pct'] = tp_pct\n",
    "                all_trades.append(current_trade)\n",
    "                balance.append(balance[-1] + tp_pct)\n",
    "                current_trade = None\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–¥–µ–ª–∫—É, –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∞—Å—å\n",
    "    if current_trade is not None:\n",
    "        current_trade['exit_date'] = df['Date'].iloc[-1]\n",
    "        current_trade['outcome'] = 'SL'\n",
    "        current_trade['profit_pct'] = -sl_pct\n",
    "        all_trades.append(current_trade)\n",
    "        balance.append(balance[-1] - sl_pct)\n",
    "\n",
    "    # –í DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
    "    trades_df = pd.DataFrame(all_trades) if all_trades else pd.DataFrame()\n",
    "\n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "    if not trades_df.empty:\n",
    "        total_profit = trades_df['profit_pct'].sum() * 100\n",
    "        tp_count = (trades_df['outcome'] == 'TP').sum()\n",
    "        sl_count = (trades_df['outcome'] == 'SL').sum()\n",
    "        max_sl_streak = (trades_df['outcome'] == 'SL').astype(int).groupby((trades_df['outcome'] != 'SL').cumsum()).sum().max()\n",
    "        \n",
    "        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º\n",
    "        trades_df['month'] = pd.to_datetime(trades_df['entry_date']).dt.to_period('M')\n",
    "        monthly_profit = trades_df.groupby('month')['profit_pct'].sum() * 100\n",
    "    else:\n",
    "        total_profit = 0\n",
    "        tp_count = 0\n",
    "        sl_count = 0\n",
    "        max_sl_streak = 0\n",
    "        monthly_profit = pd.Series()\n",
    "\n",
    "    results = {\n",
    "        'total_profit': total_profit,\n",
    "        'tp_count': tp_count,\n",
    "        'sl_count': sl_count,\n",
    "        'max_sl_streak': max_sl_streak,\n",
    "        'monthly_profit': monthly_profit,\n",
    "        'trades_df': trades_df,\n",
    "        'feature_cols_used': feature_cols\n",
    "    }\n",
    "\n",
    "    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "    if plot and not trades_df.empty:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "        # –ö—Ä–∏–≤–∞—è –∫–∞–ø–∏—Ç–∞–ª–∞ —Å –¥–∞—Ç–∞–º–∏ –∑–∞–∫—Ä—ã—Ç–∏—è —Å–¥–µ–ª–æ–∫\n",
    "        trades_df['cum_profit'] = trades_df['profit_pct'].cumsum() * 100\n",
    "\n",
    "        # –î–∞—Ç—ã –∑–∞–∫—Ä—ã—Ç–∏—è –¥–ª—è –æ—Å–∏ X\n",
    "        exit_dates = pd.to_datetime(trades_df['exit_date'])\n",
    "\n",
    "        axes[0].plot(exit_dates, trades_df['cum_profit'], label='Equity Curve', color='blue')\n",
    "        axes[0].axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "        axes[0].set_title('Equity Curve')\n",
    "        axes[0].set_xlabel('Exit Date')\n",
    "        axes[0].set_ylabel('Cumulative Profit %')\n",
    "        axes[0].legend()\n",
    "\n",
    "        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç –¥–ª—è —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç–∏\n",
    "        axes[0].xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        axes[0].xaxis.set_major_formatter(mdates.ConciseDateFormatter(mdates.AutoDateLocator()))\n",
    "        fig.autofmt_xdate()\n",
    "\n",
    "        # –ü—Ä–∏–±—ã–ª—å –ø–æ –º–µ—Å—è—Ü–∞–º\n",
    "        if not monthly_profit.empty:\n",
    "            monthly_profit.plot(kind='bar', ax=axes[1], color='green')\n",
    "            axes[1].set_title('Monthly Profit')\n",
    "            axes[1].set_ylabel('Profit %')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif plot:\n",
    "        print(\"‚ö†Ô∏è –ù–µ—Ç —Å–¥–µ–ª–æ–∫ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04f4c3-a070-4b46-90e5-bc9e9f390220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:trading_env]",
   "language": "python",
   "name": "conda-env-trading_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
