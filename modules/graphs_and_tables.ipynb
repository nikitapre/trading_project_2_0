{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c68db7-cca2-4279-be1a-d27955b1ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import joblib\n",
    "from typing import Any, Dict, List\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score, roc_auc_score, precision_recall_curve, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import shap\n",
    "from ipywidgets import widgets\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9179515-45a4-4e83-918a-4042836509d7",
   "metadata": {},
   "source": [
    "# Разметка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f4cd0-c0fc-456a-a486-150079eb6b29",
   "metadata": {},
   "source": [
    "## plot_ohlc_signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe253e7-a9e8-4e35-957a-5d87431c11d8",
   "metadata": {},
   "source": [
    "Рисует график OHLC с подсветкой buy/sell сигналов и шумных сигналов\n",
    "    \n",
    "Аргументы:\n",
    "- df с колонками *'Open','High','Low','Close','buy','sell','buy_noised','sell_noised'*\n",
    "- **start_idx**: начальный индекс участка\n",
    "- **end_idx**: конечный индекс участка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c480c2d7-d792-4c00-a025-fe13ea9dc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ohlc_signals(df, start_idx=0, end_idx=None):\n",
    "    \"\"\"\n",
    "    Рисует график OHLC с подсветкой buy/sell сигналов и шумных сигналов\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с колонками 'Open','High','Low','Close','buy','sell','buy_noised','sell_noised'\n",
    "        start_idx: начальный индекс участка\n",
    "        end_idx: конечный индекс участка\n",
    "    \"\"\"\n",
    "    if end_idx is None:\n",
    "        end_idx = len(df)\n",
    "    \n",
    "    plot_data = df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # Рисуем все ценовые линии\n",
    "    plt.plot(plot_data.index, plot_data['Close'], 'b-', label='Close', linewidth=1.5)\n",
    "    plt.plot(plot_data.index, plot_data['Open'], 'g--', label='Open', linewidth=1, alpha=0.7)\n",
    "    plt.plot(plot_data.index, plot_data['High'], 'c:', label='High', linewidth=1, alpha=0.7)\n",
    "    plt.plot(plot_data.index, plot_data['Low'], 'm:', label='Low', linewidth=1, alpha=0.7)\n",
    "    \n",
    "   \n",
    "     # Шумные сигналы покупки (более прозрачные и меньшего размера)\n",
    "    buy_noised_signals = plot_data[plot_data['buy_noised'] == 1]\n",
    "    if not buy_noised_signals.empty:\n",
    "        plt.scatter(buy_noised_signals.index, buy_noised_signals['Close'], \n",
    "                   color='blue', marker='^', s=80, label='Buy noised', \n",
    "                   zorder=3, alpha=0.6, edgecolors='darkgreen', linewidth=0.5)\n",
    "        \n",
    "    # Основные сигналы покупки\n",
    "    buy_main_signals = plot_data[plot_data['buy'] == 1]\n",
    "    if not buy_main_signals.empty:\n",
    "        plt.scatter(buy_main_signals.index, buy_main_signals['Close'], \n",
    "                   color='lightgreen', marker='^', s=80, label='Buy main', \n",
    "                   zorder=3, alpha=0.6, edgecolors='darkgreen', linewidth=0.5)\n",
    "    \n",
    "    # Основные сигналы продажи\n",
    "    sell_noised_signals = plot_data[plot_data['sell'] == 1]\n",
    "    if not sell_noised_signals.empty:\n",
    "        plt.scatter(sell_noised_signals.index, sell_noised_signals['Close'], \n",
    "                   color='lightcoral', marker='v', s=80, label='Sell main', \n",
    "                   zorder=3, alpha=0.6, edgecolors='darkred', linewidth=0.5)\n",
    "    \n",
    "    # Финальные сигналы покупки (более яркие и крупные)\n",
    "    buy_signals = plot_data[plot_data['buy_strong'] == 1]\n",
    "    if not buy_signals.empty:\n",
    "        plt.scatter(buy_signals.index, buy_signals['Close'], \n",
    "                   color='green', marker='^', s=20, label='Buy Strong', zorder=5)\n",
    "    \n",
    "    # Финальные сигналы продажи (более яркие и крупные)\n",
    "    sell_signals = plot_data[plot_data['sell_strong'] == 1]\n",
    "    if not sell_signals.empty:\n",
    "        plt.scatter(sell_signals.index, sell_signals['Close'], \n",
    "                   color='red', marker='v', s=20, label='Sell Strong', zorder=5)\n",
    "    \n",
    "    plt.title('OHLC Prices with Buy/Sell Signals')\n",
    "    plt.xlabel('Candles')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5aee6-96a5-4861-a044-3720330f7030",
   "metadata": {},
   "source": [
    "# Корреляционный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e4230d-3378-4e13-922e-a37c8c09dba7",
   "metadata": {},
   "source": [
    "## plot_corr_by_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9a3ab-4b93-49f5-8bc2-edf1d6874367",
   "metadata": {},
   "source": [
    "**plot_corr_by_distance** Строит график средней корреляции (по модулю) между target и всеми признаками.\n",
    "- по оси **y** указаны значения корреляции между целевой переменной **target** и признаками\n",
    "- по оси **x** отложено расстояние от текущей закрытой свечи до свечей на которых был проведен расчет признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b3f3367-3f0b-49ad-ad4c-2f0a9190023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_by_distance(df, target='buy', pattern=r'_(\\d+)$', min_corr=0.01):\n",
    "    \"\"\"\n",
    "    Строит график средней корреляции (по модулю) между target и признаками,\n",
    "    где в названии признака есть число (удаление от текущей цены).\n",
    "    В расчет берутся только признаки с |corr| > min_corr.\n",
    "    \"\"\"\n",
    "    corr = df.corr(numeric_only=True)[target].drop(target).abs()\n",
    "\n",
    "    # Фильтрация слабых корреляций\n",
    "    corr = corr[corr > min_corr]\n",
    "\n",
    "    distance_corrs = {}\n",
    "    for col, val in corr.items():\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            dist = int(match.group(1))\n",
    "            distance_corrs.setdefault(dist, []).append(val)\n",
    "\n",
    "    avg_corr = {dist: np.mean(vals) for dist, vals in distance_corrs.items()}\n",
    "\n",
    "    distances = sorted(avg_corr.keys())\n",
    "    values = [avg_corr[d] for d in distances]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(distances, values, marker='o')\n",
    "    plt.title('График угасания корреляции')\n",
    "    plt.xlabel('Расстояние от текущей свечи')\n",
    "    plt.ylabel('Средняя |corr|')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbec6c-02bf-4384-aacb-73859001c9a9",
   "metadata": {},
   "source": [
    "## plot_correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221dbb5-f7aa-44ef-bce7-70b752d5e82a",
   "metadata": {},
   "source": [
    "**plot_correlation_matrix** Строит тепловую карту корреляций целевой переменной и признаками\n",
    "\n",
    "Вход:\n",
    "- df с признаками и целевой переменной\n",
    "- drop_columns базовые/промежуточные колонки не требующие исследования\n",
    "- top_n - фильтр по корреляции\n",
    "- target - целевая переменная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a18d2b6f-6435-4584-adfa-87d5a2b4b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df, target=None, drop_columns=['Data', 'High', 'Low', 'Close', 'Open', 'Volume'], top_n=30):\n",
    "    \"\"\"\n",
    "    Строит корреляционную матрицу для топ-N признаков, наиболее коррелированных с целевой переменной\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с признаками\n",
    "        target: имя целевой переменной (если None - корреляция между всеми признаками)\n",
    "        drop_columns: колонки для исключения из анализа\n",
    "        top_n: количество признаков для отображения\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Удаляем ненужные колонки\n",
    "        data = df.drop(drop_columns, axis=1, errors='ignore')\n",
    "        \n",
    "        # Если указана целевая переменная - выбираем топ-N признаков по корреляции с ней\n",
    "        if target is not None and target in data.columns:\n",
    "            # Вычисляем корреляцию с целевой переменной\n",
    "            target_corr = data.corr()[target].abs().sort_values(ascending=False)\n",
    "            \n",
    "            # Берем топ-N признаков (включая саму целевую)\n",
    "            top_features = target_corr.head(top_n).index.tolist()\n",
    "            \n",
    "            # Убедимся, что целевая переменная есть в списке\n",
    "            if target not in top_features:\n",
    "                top_features.append(target)\n",
    "                \n",
    "            corr_matrix = data[top_features].corr()\n",
    "            \n",
    "        else:\n",
    "            # Стандартный подход - корреляция между всеми признаками\n",
    "            corr_matrix = data.corr()\n",
    "            \n",
    "            # Если признаков слишком много - ограничиваем топ-N\n",
    "            if len(corr_matrix) > top_n:\n",
    "                mean_abs_corr = corr_matrix.abs().mean().sort_values(ascending=False)\n",
    "                top_features = mean_abs_corr.head(top_n).index\n",
    "                corr_matrix = corr_matrix.loc[top_features, top_features]\n",
    "        \n",
    "        num_features = len(corr_matrix)\n",
    "        \n",
    "        # Динамические настройки в зависимости от количества признаков\n",
    "        if num_features <= 15:\n",
    "            figsize = (10, 8)\n",
    "            font_scale = 1.2\n",
    "            annot = True\n",
    "            label_size = 10\n",
    "        elif num_features <= 30:\n",
    "            figsize = (16, 14)\n",
    "            font_scale = 1.0\n",
    "            annot = False\n",
    "            label_size = 9\n",
    "        else:\n",
    "            figsize = (20, 18)\n",
    "            font_scale = 0.8\n",
    "            annot = False\n",
    "            label_size = 8\n",
    "            plt.rcParams['xtick.major.pad'] = 0.5\n",
    "            plt.rcParams['ytick.major.pad'] = 0.5\n",
    "        \n",
    "        # Настройка стиля\n",
    "        sns.set(font_scale=font_scale)\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Построение тепловой карты\n",
    "        heatmap = sns.heatmap(\n",
    "            corr_matrix,\n",
    "            cmap='coolwarm',\n",
    "            annot=annot,\n",
    "            fmt=\".2f\",\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.7},\n",
    "            mask=np.triu(np.ones_like(corr_matrix, dtype=bool)),\n",
    "            annot_kws={\"size\": 8} if annot else None\n",
    "        )\n",
    "        \n",
    "        # Настройка подписей осей\n",
    "        heatmap.set_xticklabels(\n",
    "            heatmap.get_xticklabels(),\n",
    "            rotation=45,\n",
    "            ha='right',\n",
    "            fontsize=label_size\n",
    "        )\n",
    "        heatmap.set_yticklabels(\n",
    "            heatmap.get_yticklabels(),\n",
    "            rotation=0,\n",
    "            fontsize=label_size\n",
    "        )\n",
    "        \n",
    "        # Формируем заголовок\n",
    "        if target is not None and target in data.columns:\n",
    "            title = f'Корреляционная матрица (топ-{num_features} признаков с \"{target}\")'\n",
    "        else:\n",
    "            title_suffix = f' (топ-{num_features} из {len(data.columns)} признаков)' if len(data.columns) > num_features else f' ({num_features} признаков)'\n",
    "            title = f'Корреляционная матрица{title_suffix}'\n",
    "            \n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при построении графика: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6be3f4-196e-4854-8d39-dd795dda6b22",
   "metadata": {},
   "source": [
    "# Визуализация признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dc0dd-ca00-4d31-a5f7-c6ae5ec61e41",
   "metadata": {},
   "source": [
    "**plot_price_with_indicators** Строит основной график цены и визуализирует используемые признаки - индикаторы.\n",
    "\n",
    "На вход подается:\n",
    "- df с колонкой цены **Close**\n",
    "- исследуемые границы графика - **start / end**\n",
    "- заголовок графика\n",
    "- список индикаторов **indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6adf2938-6d66-4dca-b62e-491b989f54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_with_indicators(df, indicators, start=-400, end=-200, colors=None, title=None):\n",
    "    \"\"\"\n",
    "    df          - DataFrame с колонками Close и индикаторами\n",
    "    indicators  - список названий индикаторов для отображения\n",
    "    start, end  - диапазон среза df\n",
    "    colors      - список цветов (опционально)\n",
    "    title       - заголовок графика (опционально)\n",
    "    \"\"\"\n",
    "    df_slice = df.iloc[start:end]\n",
    "    \n",
    "    # Настройка стиля графика\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(10, 6), facecolor='#f8f9fa')\n",
    "    \n",
    "    # цена - основная линия (жирная и четкая)\n",
    "    plt.plot(df_slice['Close'], label='Close', color='#2c3e50', linewidth=2.5, alpha=0.9)\n",
    "    plt.ylabel('Close Price', fontsize=12)\n",
    "    plt.xlabel('Minutes', fontsize=12)\n",
    "    \n",
    "    # Настройка фона области графика\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('#f0f3f5')\n",
    "    \n",
    "    # индикаторы на втором axes\n",
    "    ax2 = plt.twinx()\n",
    "    ax2.set_ylabel('Indicators', fontsize=12)\n",
    "    ax2.set_facecolor('#f0f3f5')\n",
    "    \n",
    "    if colors is None:\n",
    "        # Приглушенные цвета для индикаторов\n",
    "        colors = ['#e74c3c', '#3498db', '#27ae60', '#f39c12', '#8e44ad', \n",
    "                 '#16a085', '#d35400', '#2c3e50', '#7f8c8d', '#9b59b6']\n",
    "    \n",
    "    # Элегантные стили линий\n",
    "    line_styles = ['--', '-.', ':', '--', '-.', ':']\n",
    "    \n",
    "    for i, ind in enumerate(indicators):\n",
    "        # Штриховые линии с хорошей прозрачностью\n",
    "        ax2.plot(df_slice[ind], label=ind, \n",
    "                color=colors[i % len(colors)], \n",
    "                linestyle=line_styles[i % len(line_styles)],\n",
    "                linewidth=1.8, \n",
    "                alpha=0.7)  # оптимальная прозрачность\n",
    "    \n",
    "    # легенда\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    plt.legend(lines1 + lines2, labels1 + labels2, loc='upper left',\n",
    "              frameon=True, fancybox=True, shadow=True, fontsize=10)\n",
    "    \n",
    "    # Настройка сетки\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)  # очень легкая сетка\n",
    "    ax2.grid(False)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29007fa-9678-42ae-9e1b-58cf13d9ecae",
   "metadata": {},
   "source": [
    "# Расчёт и визуализация важности признаков на основе Mutual Information (до моделей)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce45fbb-c76a-4f16-91bc-98891241561d",
   "metadata": {},
   "source": [
    "**mutual_info_classif** вычисляет взаимную информацию между каждым признаком и целевой переменной.\\\n",
    "\n",
    "Входные данные:\n",
    "- X_train — матрица признаков\n",
    "- y_train — целевая переменная\n",
    "- top_n — количество топ-признаков для отображения\n",
    "- random_state — seed для воспроизводимости\n",
    "\n",
    "Процесс работы:\n",
    "- Вычисляет Mutual Information между каждым признаком и целевой переменной\n",
    "- Сортирует признаки по убыванию важности\n",
    "- Выводит таблицу топ-N наиболее информативных признаков\n",
    "- Строит горизонтальный барчарт для наглядной визуализации\n",
    "\n",
    "Особенности:\n",
    "- Работает с категориальными и числовыми признаками\n",
    "- Оценивает нелинейные зависимости: Может выявить сложные связи, которые пропускает линейная корреляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ad93966-6310-45e9-bc9a-096832e96529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_mutual_info(X_train, y_train, top_n=20, random_state=3):\n",
    "    \"\"\"\n",
    "    Расчёт важности признаков на основе Mutual Information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(f\"ℹ️ Calculating Mutual Information for {X_train.shape[1]} features...\")\n",
    "\n",
    "        # 1. Расчёт MI\n",
    "        mi_scores = mutual_info_classif(X_train, y_train, random_state=random_state)\n",
    "        mi_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'MI_Score': mi_scores\n",
    "        }).sort_values('MI_Score', ascending=False)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"✅ MI calculation completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # 2. Таблица топ-N\n",
    "        print(f\"\\n🔍 Top {top_n} Features by Mutual Information:\")\n",
    "        print(mi_df.head(top_n).to_markdown(index=False, floatfmt=\".4f\"))\n",
    "\n",
    "        # 3. Визуализация\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        plt.barh(mi_df['Feature'].head(top_n)[::-1], \n",
    "                 mi_df['MI_Score'].head(top_n)[::-1], \n",
    "                 color='skyblue')\n",
    "        plt.xlabel('Mutual Information Score')\n",
    "        plt.title(f'Top {top_n} Features by Mutual Information')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка при расчёте Mutual Information: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb430a-79b8-4bcb-9419-6110bcb579f8",
   "metadata": {},
   "source": [
    "# Распределение целевой переменной внутри выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901c7f9-a77b-4ce1-8af3-371104dd0019",
   "metadata": {},
   "source": [
    "## show_class_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee96d56-f787-4cd8-b5cc-14e526ee26a3",
   "metadata": {},
   "source": [
    "**show_class_balance** Анализирует и визуализирует распределение классов по выборкам\n",
    "\n",
    "Вход:\n",
    "- y: целевая переменная всего датасета\n",
    "- y_train: обучающая выборка\n",
    "- y_valid: валидационная выборка\n",
    "- y_test: тестовая выборка\n",
    "\n",
    "Выход:\n",
    "- Таблица с долями классов в каждой выборке\n",
    "- Столбчатая диаграмма распределения\n",
    "- Визуальная проверка сбалансированности данных\n",
    "\n",
    "Что делает: Сравнивает пропорции классов между разными выборками для контроля репрезентативности разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "272fcf1c-ed0d-4c0c-a2ec-c08a0685eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_class_balance(y, y_train, y_valid, y_test):\n",
    "    # Собираем данные в таблицу\n",
    "    balance_df = pd.DataFrame({\n",
    "        'Весь датасет': y.value_counts(normalize=True).round(3),\n",
    "        'Обучающая': y_train.value_counts(normalize=True).round(3),\n",
    "        'Валидационная': y_valid.value_counts(normalize=True).round(3),\n",
    "        'Тестовая': y_test.value_counts(normalize=True).round(3)\n",
    "    }).fillna(0)  # на случай отсутствующих классов\n",
    "    \n",
    "    # Выводим таблицу в стиле \"plain\"\n",
    "    print(\"📊 Баланс классов (доли):\")\n",
    "    print(\n",
    "        balance_df.to_markdown(\n",
    "            tablefmt=\"simple\",  # Чистый формат без лишних линий\n",
    "            stralign=\"center\",  # Выравнивание по центру\n",
    "            floatfmt=\".3f\"       # Формат чисел\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    balance_df.plot(kind='bar', width=0.8, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    plt.title('Распределение классов по выборкам', pad=20)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel('Доля класса')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    plt.legend(framealpha=0.9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc7cfd-10ae-436b-a72f-15074f380bd8",
   "metadata": {},
   "source": [
    "# Анализ порога классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792b7fa-9be8-4b5b-83a3-765d41bc6c0b",
   "metadata": {},
   "source": [
    "## evaluate_model_with_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91837d42-ecc5-43db-aa2f-cc2979bd4e68",
   "metadata": {},
   "source": [
    "**evaluate_model_with_threshold** Оценивает модель с подбором оптимального порога и возвращает результаты\n",
    "\n",
    "Вход:\n",
    "- model: обученная модель классификации\n",
    "- X_train, y_train: обучающая выборка\n",
    "- X_valid, y_valid: валидационная выборка\n",
    "- X_test, y_test: тестовая выборка (опционально)\n",
    "\n",
    "Выход:\n",
    "- Словарь с моделью, метриками и метаданными:\n",
    "- Обученная модель\n",
    "- Метрики (F1, Precision, Recall, ROC AUC) для всех выборок\n",
    "- Оптимальный порог классификации\n",
    "- Список использованных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "516b885e-bf5b-4f9e-bce8-0b962dee603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_threshold(model, X_train, y_train, X_valid, y_valid, X_test=None, y_test=None):\n",
    "    \"\"\"\n",
    "    Оценивает модель и возвращает результаты в формате для сохранения\n",
    "    \n",
    "    Возвращает словарь в формате:\n",
    "    {\n",
    "        'model': model,  # обученная модель\n",
    "        'metrics': {\n",
    "            'train': {метрики},\n",
    "            'valid': {метрики},\n",
    "            'test': {метрики} (если есть),\n",
    "            'optimal_threshold': float\n",
    "        },\n",
    "        'features': list,  # список фичей\n",
    "        'timestamp': str   # время оценки\n",
    "    }\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # 1. Получаем предсказанные вероятности\n",
    "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_valid_proba = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 2. Создаем диапазон порогов\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    \n",
    "    # 3. Функция для вычисления F1 при разных порогах\n",
    "    def find_best_threshold(y_true, y_proba, thresholds):\n",
    "        f1_scores = []\n",
    "        for t in thresholds:\n",
    "            y_pred = (y_proba >= t).astype(int)\n",
    "            f1_scores.append(f1_score(y_true, y_pred, zero_division=0))\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        return thresholds[best_idx], f1_scores\n",
    "    \n",
    "    # 4. Находим лучшие пороги для train и valid\n",
    "    train_best_threshold, train_f1_scores = find_best_threshold(y_train, y_train_proba, thresholds)\n",
    "    valid_best_threshold, valid_f1_scores = find_best_threshold(y_valid, y_valid_proba, thresholds)\n",
    "    \n",
    "    # 5. Вычисляем средний оптимальный порог\n",
    "    optimal_threshold = np.mean([train_best_threshold, valid_best_threshold])\n",
    "    \n",
    "    # 6. Создаем словари с метриками\n",
    "    train_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'f1_scores': train_f1_scores,\n",
    "        'precision': [precision_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'recall': [recall_score(y_train, (y_train_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_train_proba,\n",
    "        'max_f1_threshold': train_best_threshold,\n",
    "        'roc_auc': roc_auc_score(y_train, y_train_proba)  # Добавлено ROC AUC\n",
    "    }\n",
    "    \n",
    "    valid_metrics = {\n",
    "        'thresholds': thresholds,\n",
    "        'f1_scores': valid_f1_scores,\n",
    "        'precision': [precision_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'recall': [recall_score(y_valid, (y_valid_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "        'y_proba': y_valid_proba,\n",
    "        'max_f1_threshold': valid_best_threshold,\n",
    "        'roc_auc': roc_auc_score(y_valid, y_valid_proba)  # Добавлено ROC AUC\n",
    "    }\n",
    "    \n",
    "    # 7. Выводим результаты\n",
    "    print(f\"🎯 Лучший порог по F1 (Train): {train_best_threshold:.4f}\")\n",
    "    print(f\"🎯 Лучший порог по F1 (Valid): {valid_best_threshold:.4f}\")\n",
    "    print(f\"✅ Усредненный оптимальный порог: {optimal_threshold:.4f}\")\n",
    "    print(f\"\\n📊 ROC AUC Scores:\")\n",
    "    print(f\"✅ Train ROC AUC: {train_metrics['roc_auc']:.4f}\")\n",
    "    print(f\"✅ Valid ROC AUC: {valid_metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # 8. Считаем финальные метрики с усредненным порогом\n",
    "    def calculate_final_metrics(y_true, y_proba, threshold, set_name):\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        metrics = {\n",
    "            'F1': f1_score(y_true, y_pred, zero_division=0),\n",
    "            'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'ROC_AUC': roc_auc_score(y_true, y_proba)  # Добавлено ROC AUC\n",
    "        }\n",
    "        print(f\"\\n📊 {set_name} set (Threshold = {threshold:.4f}):\")\n",
    "        print(f\"✅ F1: {metrics['F1']:.4f}\")\n",
    "        print(f\"✅ Precision: {metrics['Precision']:.4f}\")\n",
    "        print(f\"✅ Recall: {metrics['Recall']:.4f}\")\n",
    "        print(f\"✅ ROC AUC: {metrics['ROC_AUC']:.4f}\")\n",
    "        return metrics\n",
    "    \n",
    "    train_metrics['final_metrics'] = calculate_final_metrics(y_train, y_train_proba, optimal_threshold, \"Train\")\n",
    "    valid_metrics['final_metrics'] = calculate_final_metrics(y_valid, y_valid_proba, optimal_threshold, \"Valid\")\n",
    "    \n",
    "    results = {\n",
    "        'train': train_metrics,\n",
    "        'valid': valid_metrics,\n",
    "        'optimal_threshold': optimal_threshold\n",
    "    }\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        test_metrics = {\n",
    "            'thresholds': thresholds,\n",
    "            'f1_scores': [f1_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'precision': [precision_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'recall': [recall_score(y_test, (y_test_proba >= t).astype(int), zero_division=0) for t in thresholds],\n",
    "            'y_proba': y_test_proba,\n",
    "            'roc_auc': roc_auc_score(y_test, y_test_proba)  # Добавлено ROC AUC\n",
    "        }\n",
    "        test_metrics['final_metrics'] = calculate_final_metrics(\n",
    "            y_test, y_test_proba, optimal_threshold, \"Test\"\n",
    "        )\n",
    "        results['test'] = test_metrics\n",
    "    \n",
    "    # 9. Визуализация (остается без изменений)\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # 1. Кривые для обучающей выборки\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(train_best_threshold, color='b', linestyle=':', label=f'Train Max F1: {train_best_threshold:.3f}')\n",
    "    plt.title('Train Selection')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 2. Кривые для валидационной выборки\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['precision'], label='Precision', color='blue')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['recall'], label='Recall', color='green')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='F1', color='red')\n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(valid_best_threshold, color='orange', linestyle=':', label=f'Valid Max F1: {valid_best_threshold:.3f}')\n",
    "    plt.title('Test Set')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 3. Сравнение F1-кривых с новым порогом\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(train_metrics['thresholds'], train_metrics['f1_scores'], label='Train F1', color='blue')\n",
    "    plt.plot(valid_metrics['thresholds'], valid_metrics['f1_scores'], label='Valid F1', color='orange')\n",
    "    \n",
    "    # Добавлена третья линия для тестовой выборки, если она есть\n",
    "    if X_test is not None and y_test is not None:\n",
    "        plt.plot(test_metrics['thresholds'], test_metrics['f1_scores'], label='Test F1', color='green')\n",
    "    \n",
    "    plt.axvline(optimal_threshold, color='k', linestyle='-', label=f'Avg Optimal: {optimal_threshold:.3f}')\n",
    "    plt.axvline(train_best_threshold, color='b', linestyle=':', alpha=0.5)\n",
    "    plt.axvline(valid_best_threshold, color='orange', linestyle=':', alpha=0.5)\n",
    "    plt.title('F1 Comparison with Optimal Threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 10. Выводим итоговые метрики в таблице (добавляем ROC AUC)\n",
    "    final_table = [\n",
    "        [\"Dataset\", \"Threshold Type\"] + list(train_metrics['final_metrics'].keys()),\n",
    "        [\"Train\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(train_metrics['final_metrics'].values()),\n",
    "        [\"Test\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(valid_metrics['final_metrics'].values())\n",
    "    ]\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        final_table.append(\n",
    "            [\"Test\", f\"Average Optimal ({optimal_threshold:.4f})\"] + list(results['test']['final_metrics'].values())\n",
    "        )\n",
    "    \n",
    "    # print(\"\\nИтоговые метрики со средним оптимальным порогом:\")\n",
    "    # print(tabulate(final_table, headers=\"firstrow\", floatfmt=\".4f\", tablefmt=\"grid\"))\n",
    "\n",
    "     # Формируем итоговый словарь в нужном формате\n",
    "    model_package = {\n",
    "        'model': model,\n",
    "        'metrics': {\n",
    "            'train': train_metrics['final_metrics'],\n",
    "            'valid': valid_metrics['final_metrics'],\n",
    "            'optimal_threshold': optimal_threshold\n",
    "        },\n",
    "        'features': list(X_train.columns),\n",
    "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    if X_test is not None and y_test is not None:\n",
    "        model_package['metrics']['test'] = results['test']['final_metrics']\n",
    "    \n",
    "    return model_package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd9cc88-f7ac-473f-89c5-a92960a8c049",
   "metadata": {},
   "source": [
    "# Интерпретация модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2958bb-0ad8-4fe7-9823-909848f4c920",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95e1ae-6bc0-4600-9caa-12549f310c3d",
   "metadata": {},
   "source": [
    "### explain_model_shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e83025-79e3-45b9-9b94-04376c5ef512",
   "metadata": {},
   "source": [
    "Функция **explain_model_shap**: \n",
    "- Вычисляет SHAP-значения для интерпретации модели\n",
    "- Анализирует важность и направление влияния признаков\n",
    "- Визуализирует топ-N наиболее значимых признаков\n",
    "\n",
    "Входные данные:\n",
    "- X_train — датафрейм с признаками\n",
    "- model — обученная модель (RandomForest, XGBoost, LogisticRegression и др.)\n",
    "- sample_size — размер подвыборки для анализа (по умолчанию 2000)\n",
    "- top_n — количество топ-признаков для отображения\n",
    "- n_jobs — количество ядер для параллельных вычислений\n",
    "\n",
    "Выходные данные:\n",
    "- DataFrame с ранжированными признаками по важности\n",
    "- Визуализация важности признаков\n",
    "\n",
    "Особенности метода:\n",
    "- Автоматическое определение типа модели (TreeExplainer, LinearExplainer)\n",
    "- Поддержка многоклассовой классификации\n",
    "- Анализ направления влияния (Positive/Negative)\n",
    "- Сравнение с feature_importances_ модели\n",
    "\n",
    "Ключевые метрики:\n",
    "- Относительная важность признаков в %\n",
    "- Направление влияния на предсказание\n",
    "- Кумулятивная важность топ-признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f6f1aa7-ff27-4c41-bbe2-dfa01c8734c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_shap(X_train, model, sample_size=2000, top_n=20, n_jobs = -1):\n",
    "    \"\"\"\n",
    "    Оборачивает расчет SHAP-важности и визуализации признаков\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame\n",
    "        Датафрейм признаков\n",
    "    model : sklearn/xgboost модель\n",
    "        Обученная модель (RandomForest, LogisticRegression, XGB и др.)\n",
    "    sample_size : int\n",
    "        Размер случайной подвыборки\n",
    "    top_n : int\n",
    "        Кол-во признаков для отображения\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total_start_time = time.time()\n",
    "        model_type = type(model).__name__\n",
    "        \n",
    "        print(f\"ℹ️ Model type: {model_type}\")\n",
    "        print(f\"ℹ️ Number of classes: {getattr(model, 'n_classes_', 'unknown')}\")\n",
    "        \n",
    "        # 1. Инициализация Explainer\n",
    "        print(\"🔄 Initializing SHAP explainer...\")\n",
    "        explainer_start = time.time()\n",
    "        if model_type in ['RandomForestClassifier', 'RandomForestRegressor', \n",
    "                          'XGBClassifier', 'XGBRegressor', \n",
    "                          'LGBMClassifier', 'LGBMRegressor']:\n",
    "            explainer = shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\")\n",
    "        elif model_type in ['LogisticRegression', 'LinearRegression']:\n",
    "            explainer = shap.LinearExplainer(model, X_train)\n",
    "        else:\n",
    "            explainer = shap.Explainer(model, X_train)\n",
    "        explainer_time = time.time() - explainer_start\n",
    "        print(f\"✅ SHAP explainer initialized in {timedelta(seconds=explainer_time)}\")\n",
    "        \n",
    "        # 2. Подвыборка\n",
    "        sample_size = min(sample_size, len(X_train))\n",
    "        sample_idx = np.random.choice(X_train.index, size=sample_size, replace=False)\n",
    "        X_sample = X_train.loc[sample_idx]\n",
    "\n",
    "        print(f\"\\n🔄 Calculating SHAP values for {sample_size} samples...\")\n",
    "        shap_start = time.time()\n",
    "\n",
    "        # Параллельная обработка\n",
    "        n_jobs = n_jobs\n",
    "        n_chunks = 4 * (os.cpu_count() or 1)\n",
    "\n",
    "        def calc_chunk(chunk):\n",
    "            return explainer.shap_values(chunk, approximate=True, check_additivity=False)\n",
    "\n",
    "        chunks = np.array_split(X_sample, n_chunks)\n",
    "        results = Parallel(n_jobs=n_jobs)(delayed(calc_chunk)(chunk) for chunk in chunks)\n",
    "\n",
    "        # Объединение результатов\n",
    "        if isinstance(results[0], list):\n",
    "            shap_values = [np.concatenate([r[i] for r in results]) for i in range(len(results[0]))]\n",
    "        else:\n",
    "            shap_values = np.concatenate(results)\n",
    "\n",
    "        shap_time = time.time() - shap_start\n",
    "        print(f\"✅ SHAP values calculated in {timedelta(seconds=shap_time)}\")\n",
    "        print(f\"⏱ Average time per sample: {shap_time/sample_size:.4f} seconds\")\n",
    "\n",
    "        # 3. Обработка SHAP\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1] if len(shap_values) == 2 else np.mean(shap_values, axis=0)\n",
    "        elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "            shap_values = shap_values[:, :, 1]\n",
    "\n",
    "        print(f\"ℹ️ Processed SHAP values shape: {shap_values.shape}\")\n",
    "\n",
    "        # 4. Анализ важности\n",
    "        print(\"\\n🔄 Calculating feature importance...\")\n",
    "        analysis_start = time.time()\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'SHAP_Importance': np.abs(shap_values).mean(axis=0),\n",
    "            'Direction': np.where(np.mean(shap_values, axis=0) > 0, 'Positive', 'Negative')\n",
    "        })\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance_df['Model_Importance'] = model.feature_importances_\n",
    "            importance_df['Model_%'] = 100 * importance_df['Model_Importance'] / importance_df['Model_Importance'].max()\n",
    "\n",
    "        importance_df['SHAP_%'] = 100 * importance_df['SHAP_Importance'] / importance_df['SHAP_Importance'].max()\n",
    "        importance_df = importance_df.sort_values('SHAP_%', ascending=False)\n",
    "        importance_df['Rank'] = range(1, len(importance_df) + 1)\n",
    "        importance_df['Cumulative_SHAP_%'] = importance_df['SHAP_%'].cumsum()\n",
    "        analysis_time = time.time() - analysis_start\n",
    "        print(f\"✅ Feature analysis completed in {timedelta(seconds=analysis_time)}\")\n",
    "\n",
    "        # 5. Таблица\n",
    "        print(\"\\n🔍 Top Features by SHAP Importance:\")\n",
    "        display_cols = ['Rank', 'Feature', 'SHAP_%', 'Direction']\n",
    "        if 'Model_%' in importance_df.columns:\n",
    "            display_cols.append('Model_%')\n",
    "        print(importance_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=\".1f\"))\n",
    "\n",
    "        print(\"\\n📊 Key Metrics:\")\n",
    "        print(f\"• Top-5 features explain: {importance_df['Cumulative_SHAP_%'].iloc[4]:.1f}%\")\n",
    "        pos_count = (importance_df['Direction'] == 'Positive').sum()\n",
    "        neg_count = (importance_df['Direction'] == 'Negative').sum()\n",
    "        print(f\"• Positive/Negative: {pos_count}/{neg_count}\")\n",
    "\n",
    "        # 6. Простая визуализация\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        colors = importance_df['Direction'].head(top_n).map({'Positive': 'tomato', 'Negative': 'dodgerblue'})\n",
    "        plt.barh(importance_df['Feature'].head(top_n)[::-1], \n",
    "                 importance_df['SHAP_%'].head(top_n)[::-1],\n",
    "                 color=colors[::-1])\n",
    "        plt.title(f'Top {top_n} Features by SHAP')\n",
    "        plt.xlabel('Relative SHAP Importance (%)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 7. Общее время\n",
    "        total_time = time.time() - total_start_time\n",
    "        print(f\"\\n⏱ Total execution time: {timedelta(seconds=total_time)}\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"Time breakdown:\")\n",
    "        print(f\"- Explainer init: {timedelta(seconds=explainer_time)}\")\n",
    "        print(f\"- SHAP values: {timedelta(seconds=shap_time)} ({shap_time/total_time*100:.1f}%)\")\n",
    "        print(f\"- Analysis: {timedelta(seconds=analysis_time)} ({analysis_time/total_time*100:.1f}%)\")\n",
    "\n",
    "        return importance_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {str(e)}\")\n",
    "        if 'shap_values' in locals():\n",
    "            print(f\"SHAP values type: {type(shap_values)}\")\n",
    "            if hasattr(shap_values, 'shape'):\n",
    "                print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "        print(f\"X_train shape: {X_train.shape if X_train is not None else 'N/A'}\")\n",
    "        if hasattr(model, 'n_features_in_'):\n",
    "            print(f\"Model features: {model.n_features_in_}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d2d63-2ead-4130-8e19-f8d23655fbcf",
   "metadata": {},
   "source": [
    "## Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b092-0b78-45c5-accf-c1fa41b8e7dd",
   "metadata": {},
   "source": [
    "### explain_model_permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54ad36-eaca-40ce-9668-511909027006",
   "metadata": {},
   "source": [
    "**explain_model_permutation** Оценивает важность признаков с помощью Permutation Importance\n",
    "\n",
    "Вход:\n",
    "- X: DataFrame с признаками\n",
    "- y: целевая переменная\n",
    "- model: обученная модель (RandomForest, XGBoost и др.)\n",
    "- scoring: метрика оценки ('f1', 'accuracy', 'roc_auc')\n",
    "- n_repeats: количество повторов для стабильности\n",
    "- top_n: количество топ-признаков для отображения\n",
    "- random_state: seed для воспроизводимости\n",
    "- n_jobs: количество ядер для параллельных вычислений\n",
    "\n",
    "Выход:\n",
    "- DataFrame с важностью признаков (Feature, Mean Importance, Std, Significant, Rank)\n",
    "- Визуализация топ-признаков с доверительными интервалами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8febae14-8416-4b20-ba44-9e67d46cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_permutation(X, y, model, scoring='f1', n_repeats=5, top_n=20, random_state=3, n_jobs = 4):\n",
    "    \"\"\"\n",
    "    Оценивает важность признаков с помощью Permutation Importance.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Признаки (X_train или X_valid)\n",
    "    y : pd.Series\n",
    "        Целевая переменная\n",
    "    model : обученная модель\n",
    "        RandomForest, LogisticRegression, XGBoost и т.д.\n",
    "    scoring : str\n",
    "        Метрика (например, 'f1', 'accuracy', 'roc_auc')\n",
    "    n_repeats : int\n",
    "        Количество повторов для случайности\n",
    "    top_n : int\n",
    "        Кол-во признаков для отображения\n",
    "    random_state : int\n",
    "        Случайное зерно для воспроизводимости\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.DataFrame — таблица важности признаков\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ℹ️ Model type: {type(model).__name__}\")\n",
    "        print(f\"ℹ️ Scoring metric: {scoring}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(\"🔄 Calculating permutation importance...\")\n",
    "        result = permutation_importance(\n",
    "            model, X, y,\n",
    "            scoring=scoring,\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"✅ Completed in {timedelta(seconds=elapsed)}\")\n",
    "\n",
    "        # Формируем датафрейм\n",
    "        importances_df = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Mean Importance': result.importances_mean,\n",
    "            'Std': result.importances_std\n",
    "        })\n",
    "        importances_df['Significant'] = importances_df['Mean Importance'] - 2 * importances_df['Std'] > 0\n",
    "        importances_df = importances_df.sort_values(by='Mean Importance', ascending=False).reset_index(drop=True)\n",
    "        importances_df['Rank'] = importances_df.index + 1\n",
    "\n",
    "        print(\"\\n🔍 Top Features by Permutation Importance:\")\n",
    "        display_cols = ['Rank', 'Feature', 'Mean Importance', 'Std', 'Significant']\n",
    "        print(importances_df.head(top_n)[display_cols].to_markdown(index=False, floatfmt=\".3f\"))\n",
    "\n",
    "        # Простая визуализация\n",
    "        top_features = importances_df.head(top_n)\n",
    "        plt.figure(figsize=(10, min(6, top_n * 0.3)))\n",
    "        bars = plt.barh(top_features['Feature'][::-1], top_features['Mean Importance'][::-1],\n",
    "                        xerr=top_features['Std'][::-1], color='mediumseagreen')\n",
    "        plt.xlabel(\"Mean Importance\")\n",
    "        plt.title(f\"Top {top_n} Features by Permutation Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return importances_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during permutation importance: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1e2d8-b399-4538-96c5-e31c23234948",
   "metadata": {},
   "source": [
    "# Сигналы модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c9837-4416-43be-80a6-11a9ae2ec468",
   "metadata": {},
   "source": [
    "**plot_predict_signals** Визуализирует OHLC график с истинными и предсказанными торговыми сигналами\n",
    "\n",
    "Аргументы:\n",
    "- df с колонками: 'Open','High','Low','Close','buy','sell'\n",
    "- y_pred: массив предсказаний модели (опционально)\n",
    "- pred_threshold: порог бинаризации предсказаний\n",
    "- start_idx: начальный индекс участка\n",
    "- end_idx: конечный индекс участка\n",
    "\n",
    "Отображает:\n",
    "- Линии OHLC цен\n",
    "- Истинные buy/sell сигналы (зеленые/красные маркеры)\n",
    "- Предсказанные buy сигналы модели (синие маркеры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73cb54ac-e8c4-4965-a37d-44305cdac3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predict_signals(df, y_pred=None, pred_threshold=0.5, start_idx=200, end_idx=500):\n",
    "    \"\"\"\n",
    "    Рисует график OHLC с подсветкой buy/sell сигналов и предсказаниями модели\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с колонками 'Open','High','Low','Close','buy','sell'\n",
    "        y_pred: массив предсказаний модели (вероятности или бинарные)\n",
    "        pred_threshold: порог для бинаризации предсказаний\n",
    "        start_idx: начальный индекс участка\n",
    "        end_idx: конечный индекс участка\n",
    "    \"\"\"\n",
    "    if end_idx is None:\n",
    "        end_idx = len(df)\n",
    "    \n",
    "    plot_data = df.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    # Добавляем предсказания модели если они переданы\n",
    "    if y_pred is not None:\n",
    "        # Бинаризуем предсказания по порогу\n",
    "        y_pred_binary = (y_pred[start_idx:end_idx] >= pred_threshold).astype(int)\n",
    "        plot_data['model_buy'] = y_pred_binary\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    # Рисуем все ценовые линии\n",
    "    plt.plot(plot_data.index, plot_data['Close'], 'b-', label='Close', linewidth=1.5, alpha=0.8)\n",
    "    plt.plot(plot_data.index, plot_data['Open'], 'g--', label='Open', linewidth=1, alpha=0.6)\n",
    "    plt.plot(plot_data.index, plot_data['High'], 'c:', label='High', linewidth=1, alpha=0.6)\n",
    "    plt.plot(plot_data.index, plot_data['Low'], 'm:', label='Low', linewidth=1, alpha=0.6)\n",
    "    \n",
    "    # Сигналы покупки (истинные)\n",
    "    buy_signals = plot_data[plot_data['buy'] == 1]\n",
    "    if not buy_signals.empty:\n",
    "        plt.scatter(buy_signals.index, buy_signals['Close'], \n",
    "                   color='green', marker='^', s=120, label='True Buy', zorder=5, alpha=0.8)\n",
    "    \n",
    "    # Сигналы продажи (истинные)\n",
    "    sell_signals = plot_data[plot_data['sell'] == 1]\n",
    "    if not sell_signals.empty:\n",
    "        plt.scatter(sell_signals.index, sell_signals['Close'], \n",
    "                   color='red', marker='v', s=120, label='True Sell', zorder=5, alpha=0.8)\n",
    "    \n",
    "    # Предсказания модели (если переданы)\n",
    "    if y_pred is not None:\n",
    "        model_buy_signals = plot_data[plot_data['model_buy'] == 1]\n",
    "        if not model_buy_signals.empty:\n",
    "            plt.scatter(model_buy_signals.index, model_buy_signals['Close'], \n",
    "                       color='blue', marker='^', s=100, label=f'Model Buy (≥{pred_threshold})', \n",
    "                       zorder=4, alpha=0.6, edgecolors='black', linewidth=1)\n",
    "    \n",
    "    plt.title(f'OHLC Prices with Buy/Sell Signals (Threshold: {pred_threshold})')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6a0c3-57fb-4c6c-b448-066f473d38d6",
   "metadata": {},
   "source": [
    "# Бэктест модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0be2b9-794b-4769-873f-e0b1bb3b56ed",
   "metadata": {},
   "source": [
    "**backtest_model** Проводит пошаговый бэктест торговой модели с TP/SL и анализирует результаты\n",
    "\n",
    "Аргументы:\n",
    "- df: DataFrame с признаками и ценовыми данными\n",
    "- model: обученная модель машинного обучения\n",
    "- X_train: тренировочные данные, для необходимых признаков\n",
    "- threshold: порог для торговых сигналов\n",
    "- tp_pct: уровень тейк-профита (%)\n",
    "- rr: соотношение риск/прибыль\n",
    "- plot: флаг отображения графиков\n",
    "\n",
    "Возвращает:\n",
    "- Общую прибыль и счетчик TP/SL сделок\n",
    "- Максимальную серию убытков\n",
    "- Помесячную статистику\n",
    "- Таблицу всех сделок\n",
    "- Графики кривой капитала и месячной прибыли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ba07626b-a20e-48f7-9657-e64bfca1f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_model(df, model, X_train, threshold=0.5, tp_pct=0.04, rr=2.0, plot=True):\n",
    "    \"\"\"\n",
    "    Пошаговый бэктест торговой модели с TP и SL.\n",
    "    После закрытия сделки следующая проверка начинается со следующей свечи.\n",
    "    Результат: метрики, таблица сделок, помесячная статистика и кривая капитала.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с данными для бэктеста\n",
    "        model: обученная модель\n",
    "        X_train: тренировочные данные (для получения feature_cols)\n",
    "        threshold: порог для входа в сделку\n",
    "        tp_pct: уровень тейк-профита в процентах\n",
    "        rr: risk-reward ratio\n",
    "        plot: строить ли графики\n",
    "    \"\"\"\n",
    "\n",
    "    # Базовые колонки (исключаем те, что могут быть в df но не в фичах)\n",
    "    base_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'buy', 'sell', \n",
    "                 'buy_strong', 'sell_strong', 'buy_noised', 'sell_noised']\n",
    "    \n",
    "    # Признаки берутся из X_train.columns\n",
    "    feature_cols = [col for col in X_train.columns if col in df.columns]\n",
    "    \n",
    "    # Проверяем, что все фичи есть в df\n",
    "    missing_features = set(X_train.columns) - set(df.columns)\n",
    "    if missing_features:\n",
    "        print(f\"⚠️ Внимание: отсутствуют фичи в df: {missing_features}\")\n",
    "        print(f\"Используем только доступные фичи: {feature_cols}\")\n",
    "\n",
    "    # Для SL\n",
    "    sl_pct = tp_pct / rr\n",
    "\n",
    "    # Предсказания (только если есть фичи)\n",
    "    if feature_cols:\n",
    "        preds = model.predict_proba(df[feature_cols])[:, 1]\n",
    "        df = df.copy()\n",
    "        df['pred'] = preds\n",
    "    else:\n",
    "        print(\"❌ Нет доступных фич для предсказания!\")\n",
    "        return None\n",
    "\n",
    "    all_trades = []\n",
    "    current_trade = None\n",
    "    i = 0\n",
    "    n = len(df)\n",
    "    balance = [0]  # кривая капитала\n",
    "\n",
    "    while i < n:\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        # Если нет сделки — ищем вход\n",
    "        if current_trade is None:\n",
    "            if row['pred'] >= threshold:\n",
    "                entry_price = row['Close']\n",
    "                tp_price = entry_price * (1 + tp_pct)\n",
    "                sl_price = entry_price * (1 - sl_pct)\n",
    "\n",
    "                current_trade = {\n",
    "                    'entry_date': row['Date'],\n",
    "                    'entry_price': entry_price,\n",
    "                    'tp_price': tp_price,\n",
    "                    'sl_price': sl_price\n",
    "                }\n",
    "        else:\n",
    "            # Проверяем условия выхода\n",
    "            if row['Low'] <= current_trade['sl_price']:\n",
    "                current_trade['exit_date'] = row['Date']\n",
    "                current_trade['outcome'] = 'SL'\n",
    "                current_trade['profit_pct'] = -sl_pct\n",
    "                all_trades.append(current_trade)\n",
    "                balance.append(balance[-1] - sl_pct)\n",
    "                current_trade = None\n",
    "                i += 1  # проверка со следующей свечи\n",
    "                continue\n",
    "\n",
    "            if row['High'] >= current_trade['tp_price']:\n",
    "                current_trade['exit_date'] = row['Date']\n",
    "                current_trade['outcome'] = 'TP'\n",
    "                current_trade['profit_pct'] = tp_pct\n",
    "                all_trades.append(current_trade)\n",
    "                balance.append(balance[-1] + tp_pct)\n",
    "                current_trade = None\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Закрываем последнюю сделку, если осталась\n",
    "    if current_trade is not None:\n",
    "        current_trade['exit_date'] = df['Date'].iloc[-1]\n",
    "        current_trade['outcome'] = 'SL'\n",
    "        current_trade['profit_pct'] = -sl_pct\n",
    "        all_trades.append(current_trade)\n",
    "        balance.append(balance[-1] - sl_pct)\n",
    "\n",
    "    # В DataFrame для анализа\n",
    "    trades_df = pd.DataFrame(all_trades) if all_trades else pd.DataFrame()\n",
    "\n",
    "    # Метрики\n",
    "    if not trades_df.empty:\n",
    "        total_profit = trades_df['profit_pct'].sum() * 100\n",
    "        tp_count = (trades_df['outcome'] == 'TP').sum()\n",
    "        sl_count = (trades_df['outcome'] == 'SL').sum()\n",
    "        max_sl_streak = (trades_df['outcome'] == 'SL').astype(int).groupby((trades_df['outcome'] != 'SL').cumsum()).sum().max()\n",
    "        \n",
    "        # Разбивка по месяцам\n",
    "        trades_df['month'] = pd.to_datetime(trades_df['entry_date']).dt.to_period('M')\n",
    "        monthly_profit = trades_df.groupby('month')['profit_pct'].sum() * 100\n",
    "    else:\n",
    "        total_profit = 0\n",
    "        tp_count = 0\n",
    "        sl_count = 0\n",
    "        max_sl_streak = 0\n",
    "        monthly_profit = pd.Series()\n",
    "\n",
    "    results = {\n",
    "        'total_profit': total_profit,\n",
    "        'tp_count': tp_count,\n",
    "        'sl_count': sl_count,\n",
    "        'max_sl_streak': max_sl_streak,\n",
    "        'monthly_profit': monthly_profit,\n",
    "        'trades_df': trades_df,\n",
    "        'feature_cols_used': feature_cols\n",
    "    }\n",
    "\n",
    "    # Построение графиков\n",
    "    if plot and not trades_df.empty:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "        # Кривая капитала с датами закрытия сделок\n",
    "        trades_df['cum_profit'] = trades_df['profit_pct'].cumsum() * 100\n",
    "\n",
    "        # Даты закрытия для оси X\n",
    "        exit_dates = pd.to_datetime(trades_df['exit_date'])\n",
    "\n",
    "        axes[0].plot(exit_dates, trades_df['cum_profit'], label='Equity Curve', color='blue')\n",
    "        axes[0].axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "        axes[0].set_title('Equity Curve')\n",
    "        axes[0].set_xlabel('Exit Date')\n",
    "        axes[0].set_ylabel('Cumulative Profit %')\n",
    "        axes[0].legend()\n",
    "\n",
    "        # Форматирование дат для удобочитаемости\n",
    "        axes[0].xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        axes[0].xaxis.set_major_formatter(mdates.ConciseDateFormatter(mdates.AutoDateLocator()))\n",
    "        fig.autofmt_xdate()\n",
    "\n",
    "        # Прибыль по месяцам\n",
    "        if not monthly_profit.empty:\n",
    "            monthly_profit.plot(kind='bar', ax=axes[1], color='green')\n",
    "            axes[1].set_title('Monthly Profit')\n",
    "            axes[1].set_ylabel('Profit %')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif plot:\n",
    "        print(\"⚠️ Нет сделок для построения графиков\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04f4c3-a070-4b46-90e5-bc9e9f390220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:trading_env]",
   "language": "python",
   "name": "conda-env-trading_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
